{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "This Notebook simulates the MARL behavior of a multi-agent WLAN with uncoordinated BSS's. It calls a variety of classes to generate RL instances such as different MAB exploration algorithms (e.g., e-greedy, exploration-first, Thompson Sampling, UCB1, etc.), contextual MABs, and Q-learning. Including new RL models to the project should be straightforward. The RL algorithms should evolve given a holistic dataset where all the possible system (or global) configurations are pre-simulated. That is, the framework maps the global configuration reached through the MARL interaction, queries the resulting performance of each BSS in the dataset at that system status, and feeds the corresponding value to each learning instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import tensorflow as tf\n",
    "#import keras\n",
    "# from sklearn import linear_model\n",
    "# from sklearn import metrics\n",
    "# from sklearn import model_selection\n",
    "# from sklearn import svm\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Activation\n",
    "# from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten\n",
    "# from keras.optimizers import SGD\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import random\n",
    "import math\n",
    "from auxiliary_methods import * \n",
    "import rl_models as mab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare dataset\n",
    "\n",
    "The deployment consists of 4 BSS's with one AP and one STA each. As for the interference matrix, the numbers in the cells represent the minimum bandwidth in MHz resulting in an overlap between two APs given the transmission power (14 dBm), the CCA level (-82 dBm), and the path loss model (TMB). So, for instance, a value of 40 MHz indicates that two APs would overlap if the one transmitting uses 40 MHz or less. For example, APs A and C only overlap for 20 MHz transmission, while A and D do always overlap no matter the bandwidth.\n",
    "\n",
    "<img src=\"../images/toy_scenario_deployment.png\" alt=\"WLAN deployment\" style=\"width: 620px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset datasets/dataset_multiagents_2.csv ...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1679616 entries, 0 to 1679615\n",
      "Data columns (total 53 columns):\n",
      "sim_code          1679616 non-null object\n",
      "bss_A_code        1679616 non-null object\n",
      "action_ix_A       1679616 non-null int64\n",
      "status_ix_A       1679616 non-null int64\n",
      "primary_A         1679616 non-null int64\n",
      "max_bw_ix_A       1679616 non-null int64\n",
      "load_ix_A         1679616 non-null int64\n",
      "load_A            1679616 non-null float64\n",
      "thr_A             1679616 non-null float64\n",
      "d_A               1679616 non-null float64\n",
      "rts_lost_A        1679616 non-null int64\n",
      "rts_sent_A        1679616 non-null int64\n",
      "frames_lost_A     1679616 non-null int64\n",
      "frames_sent_A     1679616 non-null int64\n",
      "bss_B_code        1679616 non-null object\n",
      "action_ix_B       1679616 non-null int64\n",
      "status_ix_B       1679616 non-null int64\n",
      "primary_B         1679616 non-null int64\n",
      "max_bw_ix_B       1679616 non-null int64\n",
      "load_ix_B         1679616 non-null int64\n",
      "load_B            1679616 non-null float64\n",
      "thr_B             1679616 non-null float64\n",
      "d_B               1679616 non-null float64\n",
      "rts_lost_B        1679616 non-null int64\n",
      "rts_sent_B        1679616 non-null int64\n",
      "frames_lost_B     1679616 non-null int64\n",
      "frames_sent_B     1679616 non-null int64\n",
      "bss_C_code        1679616 non-null object\n",
      "action_ix_C       1679616 non-null int64\n",
      "status_ix_C       1679616 non-null int64\n",
      "primary_C         1679616 non-null int64\n",
      "max_bw_ix_C       1679616 non-null int64\n",
      "load_ix_C         1679616 non-null int64\n",
      "load_C            1679616 non-null float64\n",
      "thr_C             1679616 non-null float64\n",
      "d_C               1679616 non-null float64\n",
      "rts_lost_C        1679616 non-null int64\n",
      "rts_sent_C        1679616 non-null int64\n",
      "frames_lost_C     1679616 non-null int64\n",
      "frames_sent_C     1679616 non-null int64\n",
      "bss_D_code        1679616 non-null object\n",
      "action_ix_D       1679616 non-null int64\n",
      "status_ix_D       1679616 non-null int64\n",
      "primary_D         1679616 non-null int64\n",
      "max_bw_ix_D       1679616 non-null int64\n",
      "load_ix_D         1679616 non-null int64\n",
      "load_D            1679616 non-null float64\n",
      "thr_D             1679616 non-null float64\n",
      "d_D               1679616 non-null float64\n",
      "rts_lost_D        1679616 non-null int64\n",
      "rts_sent_D        1679616 non-null int64\n",
      "frames_lost_D     1679616 non-null int64\n",
      "frames_sent_D     1679616 non-null int64\n",
      "dtypes: float64(12), int64(36), object(5)\n",
      "memory usage: 679.2+ MB\n",
      "None\n",
      " ----------------------------------------\n",
      "                                            sim_code bss_A_code  action_ix_A  \\\n",
      "0   KOMONDOR SIMULATION 'sim_status0000001' (seed...          A            1   \n",
      "1   KOMONDOR SIMULATION 'sim_status0000002' (seed...          A            1   \n",
      "2   KOMONDOR SIMULATION 'sim_status0000003' (seed...          A            1   \n",
      "3   KOMONDOR SIMULATION 'sim_status0000004' (seed...          A            1   \n",
      "4   KOMONDOR SIMULATION 'sim_status0000005' (seed...          A            1   \n",
      "\n",
      "   status_ix_A  primary_A  max_bw_ix_A  load_ix_A  load_A  thr_A     d_A  \\\n",
      "0            1          0            1          1  1666.6  16.73   45.68   \n",
      "1            1          0            1          1  1666.6  11.07  125.61   \n",
      "2            1          0            1          1  1666.6  11.08  125.31   \n",
      "3            1          0            1          1  1666.6  15.73   53.10   \n",
      "4            1          0            1          1  1666.6  11.75   95.78   \n",
      "\n",
      "        ...        primary_D  max_bw_ix_D  load_ix_D   load_D  thr_D    d_D  \\\n",
      "0       ...                0            1          1   1666.6  19.96   8.52   \n",
      "1       ...                0            1          2   4166.5  36.62  39.66   \n",
      "2       ...                0            1          3  12499.5  39.32  43.88   \n",
      "3       ...                0            2          1   1666.6  20.00  12.79   \n",
      "4       ...                0            2          2   4166.5  40.59  28.10   \n",
      "\n",
      "   rts_lost_D  rts_sent_D  frames_lost_D  frames_sent_D   \n",
      "0          44         911              0             867  \n",
      "1          30         404              0             374  \n",
      "2          23         416              0             393  \n",
      "3          35         852             36             817  \n",
      "4          31         402             31             371  \n",
      "\n",
      "[5 rows x 53 columns]\n",
      " ----------------------------------------\n",
      "Number of entries (x,y) in the data set:  1679616\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'datasets/dataset_multiagents_2.csv'\n",
    "print('Reading dataset', dataset_path, '...')\n",
    "df = pd.read_csv(dataset_path, sep=';')\n",
    "print(df.info())  # Overview of data set\n",
    "print(' ----------------------------------------')\n",
    "print(df.head())  # Overview of data set\n",
    "num_samples = len(df.index)\n",
    "print(' ----------------------------------------')\n",
    "print('Number of entries (x,y) in the data set: ', str(num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query specific entries\n",
    "Query entries of interes for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# query by column values\n",
    "# list_df = df.loc[(df['primary_A'] == 0)\\\n",
    "#        & (df['primary_B'] == 1)\\\n",
    "#        & (df['primary_C'] == 2)\\\n",
    "#        & (df['primary_D'] == 3)]\n",
    "\n",
    "# print(list_df.head())  # Overview of data set\n",
    "\n",
    "# #query by index\n",
    "# particular_row = df.iloc[100]\n",
    "# print(particular_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new features\n",
    "Create new features (or columns) of interest by operating the already existing ones in the dataset:\n",
    "- $s_{\\text{A}} = \\Gamma_\\text{A}/(\\ell_\\text{A}\\text{[Mbps]})$\n",
    "- $s_{\\text{B}} = \\Gamma_\\text{B}/(\\ell_\\text{B}\\text{[Mbps]})$\n",
    "- $s_{\\text{min}} = \\min(s_\\text{A},s_\\text{B})$\n",
    "- $s_{\\text{mean}} = \\text{mean}(s_\\text{A},s_\\text{B})$\n",
    "- $d_{\\text{max}} = \\max(d_\\text{A},d_\\text{B})$\n",
    "- $d_{\\text{mean}} = \\text{mean}(d_\\text{A},d_\\text{B})$\n",
    "\n",
    "where $\\Gamma$, $s$, and $d$, represent throughput, throughput satisfaction, and delay, respectively.\n",
    "\n",
    "Variables:\n",
    "- `df_throughput`: throughput dataframe (trh_A, thr_B, thr_C, thr_D). A table.\n",
    "- `df_sat`: satisfaction dataframe (sat_A, sat_B, sat_C, sat_D). A table. Results from operating the throughput and the load.\n",
    "- `df_min_sat`: minimum satisfaction dataframe (min_sat). A column resulting from picking the minimum value of each row in `df_sat`.\n",
    "- `df_mean_sat`: mean satisfaction dataframe (mean_sat). A column resulting from computing the mean value of each row in `df_sat`.\n",
    "- `df_delay`: delay dataframe (d_A, d_B, d_C, d_D). A table.\n",
    "- `df_max_delay`: max delay dataframe (max_delay). A column resulting from picking the max value of each row in `df_delay`.\n",
    "- `df_mean_delay`: mean delay dataframe (mean_delay). A column resulting from computing the mean value of each row in `df_delay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create min and mean throughput satisfaction columns\n",
    "df_throughput = df[['thr_A', 'thr_B', 'thr_C', 'thr_D']]\n",
    "FACTOR_PKTPERSEC_TO_MBPS = 83.33 # Packet size is 12,000 bits\n",
    "df_load = df[['load_A','load_B', 'load_C', 'load_D']] / FACTOR_PKTPERSEC_TO_MBPS\n",
    "\n",
    "# satisfaction\n",
    "data_sat = {'sat_A': df_throughput['thr_A'] / df_load['load_A'],\\\n",
    "            'sat_B': df_throughput['thr_B'] / df_load['load_B'],\\\n",
    "            'sat_C': df_throughput['thr_C'] / df_load['load_C'],\\\n",
    "            'sat_D': df_throughput['thr_D'] / df_load['load_D']}\n",
    "df_sat = pd.DataFrame (data_sat, columns = ['sat_A','sat_B', 'sat_C', 'sat_D'])\n",
    "\n",
    "# cleaning data: set satisfaction values > 1 to 1\n",
    "a = np.array(df_sat['sat_A'].values.tolist())\n",
    "df_sat['sat_A'] = np.where(a > 1, 1, a).tolist()\n",
    "a = np.array(df_sat['sat_B'].values.tolist())\n",
    "df_sat['sat_B'] = np.where(a > 1, 1, a).tolist()\n",
    "a = np.array(df_sat['sat_C'].values.tolist())\n",
    "df_sat['sat_C'] = np.where(a > 1, 1, a).tolist()\n",
    "a = np.array(df_sat['sat_D'].values.tolist())\n",
    "df_sat['sat_D'] = np.where(a > 1, 1, a).tolist()\n",
    "\n",
    "# select minimum and mean satisfaction over all the BSS's for each dataset entry\n",
    "df_min_sat = df_sat.min(axis=1)\n",
    "df_min_sat.columns = ['min_sat']\n",
    "df_mean_sat = df_sat.mean(axis=1)\n",
    "df_mean_sat.columns = ['mean_sat']\n",
    "\n",
    "# include satisfaction columns to the general dataframe df\n",
    "df['sat_A'] = data_sat['sat_A']\n",
    "df['sat_B'] = data_sat['sat_B']\n",
    "df['sat_C'] = data_sat['sat_C']\n",
    "df['sat_D'] = data_sat['sat_D']\n",
    "df['min_sat'] = df_min_sat\n",
    "df['mean_sat'] = df_mean_sat\n",
    "\n",
    "# convert 0-valued delays to maximum one since it represents no TXs successful\n",
    "MAX_DELAY = 5000 # 5000 ms is the simulation duration. So, it would be the max delay.\n",
    "df.loc[df['d_A']==0, 'd_A'] = MAX_DELAY\n",
    "df.loc[df['d_B']==0, 'd_B'] = MAX_DELAY\n",
    "df.loc[df['d_C']==0, 'd_C'] = MAX_DELAY\n",
    "df.loc[df['d_D']==0, 'd_D'] = MAX_DELAY\n",
    "\n",
    "# create max and mean delay columns\n",
    "df_delay = df[['d_A', 'd_B', 'd_C', 'd_D']]\n",
    "\n",
    "df_mean_delay = df_delay.mean(axis=1)\n",
    "df_mean_delay.columns = ['mean_delay']\n",
    "df_max_delay = df_delay.max(axis=1)\n",
    "df_max_delay.columns = ['max_delay']\n",
    "\n",
    "# include max and mean delay to general dataframe df\n",
    "df['max_delay'] = df_max_delay\n",
    "df['mean_delay'] = df_max_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dataset\n",
    "Check the distribution of parameters to overview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "THR_LIM = [-10, 160]\n",
    "SAT_LIM = [-0.1, 1.1]\n",
    "DELAY_LIM = [-10, 1000]\n",
    "\n",
    "# # -- Throughput --\n",
    "\n",
    "# df_A = df['thr_A']\n",
    "# df_A.columns = ['thr_A']\n",
    "# df_B = df['thr_B']\n",
    "# df_B.columns = ['thr_B']\n",
    "# df_C = df['thr_C']\n",
    "# df_C.columns = ['thr_C']\n",
    "# df_D = df['thr_D']\n",
    "# df_D.columns = ['thr_D']\n",
    "\n",
    "# %matplotlib inline\n",
    "# plot_data_pdf(df_A, df_A.columns[0], 'density ' + df_A.columns[0], THR_LIM)\n",
    "# plot_data_pdf(df_B, df_B.columns[0], 'density ' + df_B.columns[0], THR_LIM)\n",
    "# plot_data_pdf(df_C, df_C.columns[0], 'density ' + df_C.columns[0], THR_LIM)\n",
    "# plot_data_pdf(df_D, df_D.columns[0], 'density ' + df_D.columns[0], THR_LIM)\n",
    "\n",
    "\n",
    "# # -- Satisfaction --\n",
    "\n",
    "# df_A = data_sat['sat_A']\n",
    "# df_A.columns = ['sat_A']\n",
    "# df_B = data_sat['sat_B']\n",
    "# df_B.columns = ['sat_B']\n",
    "# df_C = data_sat['sat_C']\n",
    "# df_C.columns = ['sat_C']\n",
    "# df_D = data_sat['sat_D']\n",
    "# df_D.columns = ['sat_D']\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "# plot_data_pdf(df_A, df_A.columns[0], 'density ' + df_A.columns[0], SAT_LIM)\n",
    "# plot_data_pdf(df_B, df_B.columns[0], 'density ' + df_B.columns[0], SAT_LIM)\n",
    "# plot_data_pdf(df_C, df_C.columns[0], 'density ' + df_C.columns[0], SAT_LIM)\n",
    "# plot_data_pdf(df_D, df_D.columns[0], 'density ' + df_D.columns[0], SAT_LIM)\n",
    "\n",
    "\n",
    "# # -- Delay --\n",
    "# df_A = df['d_A']\n",
    "# df_A.columns = ['d_A']\n",
    "# df_B = df['d_B']\n",
    "# df_B.columns = ['d_B']\n",
    "# df_C = df['d_C']\n",
    "# df_C.columns = ['d_C']\n",
    "# df_D = df['d_D']\n",
    "# df_D.columns = ['d_D']\n",
    "\n",
    "# plot_data_pdf(df_A, df_A.columns[0], 'density ' + df_A.columns[0], DELAY_LIM)\n",
    "# plot_data_pdf(df_B, df_B.columns[0], 'density ' + df_B.columns[0], DELAY_LIM)\n",
    "# plot_data_pdf(df_C, df_C.columns[0], 'density ' + df_C.columns[0], DELAY_LIM)\n",
    "# plot_data_pdf(df_D, df_D.columns[0], 'density ' + df_D.columns[0], DELAY_LIM)\n",
    "\n",
    "# # -- Global performance metrics --\n",
    "# plot_data_pdf(df_min_sat, df_min_sat.columns[0], 'density ' + df_min_sat.columns[0], SAT_LIM)\n",
    "# plot_data_pdf(df_max_delay, df_max_delay.columns[0], 'density ' + df_max_delay.columns[0], DELAY_LIM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select input/output $(x,y)$\n",
    "Select features $x$ and performance metrics $y$ to assess in the ML process.\n",
    "For instance, $x$ could be the primary, max bw index, and load of each BSS, and the output simply the minimum satisfaction experienced by the less favoured BSS in the WLAN:\n",
    "\n",
    "- $x = (p_\\text{A},b_\\text{A},\\ell_\\text{A},p_\\text{B},b_\\text{B},\\ell_\\text{B},p_\\text{C},b_\\text{C},\\ell_\\text{C},p_\\text{D},b_\\text{D},\\ell_\\text{D})$\n",
    "- $y = s_\\text{min}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by load (if desired)\n",
    "filter dataset by load.\n",
    "Variables:\n",
    "- `df_x`: set of input samples $x$\n",
    "- `metric_to_optimize`: string determining the performance metric to optimize. Should be 'satis' or 'delay' for minimum satisfaction and maximum delay, respectively.\n",
    "- `df_y`: set of output samples $y$ (glboal metric to optimize)\n",
    "- `df_y_A`: set of output samples $y_\\text{A}$ (indvidual metric)\n",
    "- `LOAD_MBPS`: load $\\ell$ in Mbps to filter the dataset by. Should be 20, 50, or 150.\n",
    "- `df_x_filtered`: set of input samples $x$ filtered by the load $\\ell=$LOAD_MBPS\n",
    "- `df_y_filtered`: set of otuput samples $y$ filtered by the load $\\ell=$LOAD_MBPS\n",
    "- `df_y_A_filtered`: set of output samples $y_\\text{A}$ filtered by the load $\\ell=$LOAD_MBPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of the WHOLE dataset (metric_to_optimize = \"satis\"):\n",
      "- BSS A: min = 0.00 - mean = 0.48 - max = 1.00\n",
      "- BSS B: min = 0.00 - mean = 0.67 - max = 1.00\n",
      "- BSS C: min = 0.00 - mean = 0.57 - max = 1.00\n",
      "- BSS D: min = 0.00 - mean = 0.71 - max = 1.00\n",
      "Plotting output pdf...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x: input\n",
    "df_x = df[['primary_A', 'max_bw_ix_A', 'load_ix_A',\\\n",
    "           'primary_B', 'max_bw_ix_B', 'load_ix_B',\\\n",
    "           'primary_C', 'max_bw_ix_C', 'load_ix_C',\\\n",
    "           'primary_D', 'max_bw_ix_D', 'load_ix_D']]\n",
    "\n",
    "# y: metric_to_optimize should be 'satis' or 'delay' for satisfaction and delay, respectively\n",
    "metric_to_optimize = 'satis'\n",
    "#metric_to_optimize = 'delay'\n",
    "if metric_to_optimize == 'delay':\n",
    "    df_y = df_max_delay\n",
    "    df_y.columns = ['max_delay']\n",
    "    df_y_A = df_delay['d_A']\n",
    "    df_y_B = df_delay['d_B']\n",
    "    df_y_C = df_delay['d_C']\n",
    "    df_y_D = df_delay['d_D']\n",
    "elif metric_to_optimize == 'satis':\n",
    "    df_y = df_min_sat\n",
    "    df_y.columns = ['min_sat']\n",
    "    df_y_A = df_sat['sat_A']\n",
    "    df_y_B = df_sat['sat_B']\n",
    "    df_y_C = df_sat['sat_C']\n",
    "    df_y_D = df_sat['sat_D']\n",
    "    df_y_mean = df_mean_sat\n",
    "    df_y_mean.columns = ['df_mean_sat'] \n",
    "\n",
    "    \n",
    "# Filter by load? LOAD_MBPS sets the load in Mbps to be set in ALL the BSS's.\n",
    "filter_by_load = True\n",
    "LOAD_MBPS = 50;\n",
    "if filter_by_load:\n",
    "    # We assume first that the load is fixed and the same for every BSS\n",
    "    ixs_load = df.index[(df['load_A'] == LOAD_MBPS* FACTOR_PKTPERSEC_TO_MBPS)\\\n",
    "                        & (df['load_B'] == LOAD_MBPS*FACTOR_PKTPERSEC_TO_MBPS)\\\n",
    "                        & (df['load_C'] == LOAD_MBPS*FACTOR_PKTPERSEC_TO_MBPS)\\\n",
    "                        & (df['load_D'] == LOAD_MBPS*FACTOR_PKTPERSEC_TO_MBPS)].tolist()\n",
    "    if 'load_ix_A' in df_x:\n",
    "        del df_x['load_ix_A']\n",
    "    if 'load_ix_B' in df_x:\n",
    "        del df_x['load_ix_B']\n",
    "    if 'load_ix_C' in df_x:\n",
    "        del df_x['load_ix_C']\n",
    "    if 'load_ix_D' in df_x:\n",
    "        del df_x['load_ix_D']\n",
    "        \n",
    "    df_x_filtered = df_x.loc[ixs_load]\n",
    "    df_y_filtered = df_y.loc[ixs_load]\n",
    "    \n",
    "    # We first assume constant and same load at every AP\n",
    "    # Loads: [20 50 150] Mbps\n",
    "\n",
    "    df_y_A_filtered = df_y_A.loc[ixs_load]\n",
    "    df_y_B_filtered = df_y_B.loc[ixs_load]\n",
    "    df_y_C_filtered = df_y_C.loc[ixs_load]\n",
    "    df_y_D_filtered = df_y_D.loc[ixs_load]\n",
    "    \n",
    "    df_y_mean_filtered = df_y_mean.loc[ixs_load]\n",
    "\n",
    "else:\n",
    "    df_x_filtered = df_x\n",
    "    df_y_filtered = df_y\n",
    "\n",
    "df_y_filtered.columns = [df_y.columns[0]]\n",
    "num_samples_filtered = len(df_y_filtered.index)\n",
    "\n",
    "df_y_mean_filtered.columns = [df_y_mean.columns[0]]\n",
    "\n",
    "print('Overview of the WHOLE dataset (metric_to_optimize = \"%s\"):' % metric_to_optimize)\n",
    "print('- BSS A: min = %.2f - mean = %.2f - max = %.2f' % (df_y_A.min(),df_y_A.mean(),df_y_A.max()))\n",
    "print('- BSS B: min = %.2f - mean = %.2f - max = %.2f' % (df_y_B.min(),df_y_B.mean(),df_y_B.max()))\n",
    "print('- BSS C: min = %.2f - mean = %.2f - max = %.2f' % (df_y_C.min(),df_y_C.mean(),df_y_C.max()))\n",
    "print('- BSS D: min = %.2f - mean = %.2f - max = %.2f' % (df_y_D.min(),df_y_D.mean(),df_y_D.max()))\n",
    "\n",
    "# Plot distribution of the selected performance metric to be optimized\n",
    "%matplotlib inline\n",
    "plot_data_pdf(df_y_filtered, df_y_filtered.columns[0], 'density ' + df_y_filtered.columns[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy variables (binary categorical representation)\n",
    "Generate dummy input, i.e., translate $x$ dimensions to categorical.\n",
    "\n",
    "Note: this is a refinment step. Depending on the selected ML framework, dummy variables may not be necessary. In particular, we would me moving $x$ to have from 8 (1 $p$ value and 1 $b$ value per each of the 4 BSS's) to 28 (4 $p$ values and 3 $b$ values) dimensions.\n",
    "\n",
    "E.g., since primary $p\\in\\{0,1,2,3\\}$:\n",
    "- $p=0 \\rightarrow \\{p_0 = 1, p_1 = 0, p_2 = 0, p_3 = 0\\}$\n",
    "- $p=1 \\rightarrow \\{p_0 = 0, p_1 = 1, p_2 = 0, p_3 = 0\\}$\n",
    "- $p=2 \\rightarrow \\{p_0 = 0, p_1 = 0, p_2 = 1, p_3 = 0\\}$\n",
    "- $p=3 \\rightarrow \\{p_0 = 0, p_1 = 0, p_2 = 0, p_3 = 1\\}$\n",
    "\n",
    "where $p_i = 1$ if channel $p=i$, and $p_i = 0$ otherwise.\n",
    "\n",
    "Variables:\n",
    "- `df_x_filtered_dummy`: set of input samples $x$ filtered by the load $\\ell=$LOAD_MBPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x filtered (dimension 8):\n",
      "       primary_A  max_bw_ix_A  primary_B  max_bw_ix_B  primary_C  max_bw_ix_C  \\\n",
      "47989          0            1          0            1          0            1   \n",
      "47992          0            1          0            1          0            1   \n",
      "47995          0            1          0            1          0            1   \n",
      "47998          0            1          0            1          0            1   \n",
      "48001          0            1          0            1          0            1   \n",
      "\n",
      "       primary_D  max_bw_ix_D  \n",
      "47989          0            1  \n",
      "47992          0            2  \n",
      "47995          0            3  \n",
      "47998          1            1  \n",
      "48001          1            2  \n",
      "input x filtered dummy (dimension 28):\n",
      "       primary_A_0  primary_A_1  primary_A_2  primary_A_3  max_bw_ix_A_1  \\\n",
      "47989            1            0            0            0              1   \n",
      "47992            1            0            0            0              1   \n",
      "47995            1            0            0            0              1   \n",
      "47998            1            0            0            0              1   \n",
      "48001            1            0            0            0              1   \n",
      "\n",
      "       max_bw_ix_A_2  max_bw_ix_A_3  primary_B_0  primary_B_1  primary_B_2  \\\n",
      "47989              0              0            1            0            0   \n",
      "47992              0              0            1            0            0   \n",
      "47995              0              0            1            0            0   \n",
      "47998              0              0            1            0            0   \n",
      "48001              0              0            1            0            0   \n",
      "\n",
      "           ...        max_bw_ix_C_1  max_bw_ix_C_2  max_bw_ix_C_3  \\\n",
      "47989      ...                    1              0              0   \n",
      "47992      ...                    1              0              0   \n",
      "47995      ...                    1              0              0   \n",
      "47998      ...                    1              0              0   \n",
      "48001      ...                    1              0              0   \n",
      "\n",
      "       primary_D_0  primary_D_1  primary_D_2  primary_D_3  max_bw_ix_D_1  \\\n",
      "47989            1            0            0            0              1   \n",
      "47992            1            0            0            0              0   \n",
      "47995            1            0            0            0              0   \n",
      "47998            0            1            0            0              1   \n",
      "48001            0            1            0            0              0   \n",
      "\n",
      "       max_bw_ix_D_2  max_bw_ix_D_3  \n",
      "47989              0              0  \n",
      "47992              1              0  \n",
      "47995              0              1  \n",
      "47998              0              0  \n",
      "48001              1              0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate proper input x by creating dummy variables for each feature (p,b)\n",
    "if filter_by_load:\n",
    "    df_x_filtered_dummy = pd.get_dummies(df_x_filtered,\\\n",
    "                                   prefix=['primary_A', 'max_bw_ix_A',\\\n",
    "                                           'primary_B', 'max_bw_ix_B',\\\n",
    "                                           'primary_C', 'max_bw_ix_C',\\\n",
    "                                           'primary_D', 'max_bw_ix_D'],\\\n",
    "                                   columns=['primary_A', 'max_bw_ix_A',\\\n",
    "                                            'primary_B', 'max_bw_ix_B',\\\n",
    "                                            'primary_C', 'max_bw_ix_C',\\\n",
    "                                            'primary_D', 'max_bw_ix_D'])\n",
    "else:\n",
    "    df_x_filtered_dummy = pd.get_dummies(df_x_filtered,\\\n",
    "                                   prefix=['primary_A', 'max_bw_ix_A',\\\n",
    "                                           'primary_B', 'max_bw_ix_B',\\\n",
    "                                           'primary_C', 'max_bw_ix_C',\\\n",
    "                                           'primary_D', 'max_bw_ix_D'],\\\n",
    "                                   columns=['primary_A', 'max_bw_ix_A',\\\n",
    "                                            'primary_B', 'max_bw_ix_B',\\\n",
    "                                            'primary_C', 'max_bw_ix_C',\\\n",
    "                                            'primary_D', 'max_bw_ix_D'])\n",
    "    \n",
    "X_FILTERED_DIMENSION = len(df_x_filtered.columns)\n",
    "X_FILTERED_DUMMY_DIMENSION = len(df_x_filtered_dummy.columns)\n",
    "\n",
    "print('input x filtered (dimension %d):' % X_FILTERED_DIMENSION)\n",
    "print(df_x_filtered.head())\n",
    "\n",
    "print('input x filtered dummy (dimension %d):' % X_FILTERED_DUMMY_DIMENSION)\n",
    "print(df_x_filtered_dummy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final filtered dataset\n",
    "Dataset containing filtered input (dummy or raw) and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.concat([df_x_filtered, df_y_filtered], axis=1, sort=False)\n",
    "df_filtered_dummy = pd.concat([df_x_filtered_dummy, df_y_filtered], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of filtered dataset\n",
    "Check out the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of the FILTERED dataset (load 50 Mbps, metric_to_optimize = \"satis\"):\n",
      "- min = 0.00\n",
      "- mean = 0.26\n",
      "- max = 1.00\n",
      "- objective_y = 1.00\n",
      "- objective_action_ix = 60328\n",
      "   * num_optimal_confs = 416/20736 (2.01 %)\n",
      "Optimal global configuration:\n",
      "sim_code           KOMONDOR SIMULATION 'sim_status0060329' (seed...\n",
      "bss_A_code                                                        A\n",
      "action_ix_A                                                       1\n",
      "status_ix_A                                                       2\n",
      "primary_A                                                         0\n",
      "max_bw_ix_A                                                       1\n",
      "load_ix_A                                                         2\n",
      "load_A                                                       4166.5\n",
      "thr_A                                                         50.33\n",
      "d_A                                                            3.37\n",
      "rts_lost_A                                                        0\n",
      "rts_sent_A                                                     2678\n",
      "frames_lost_A                                                     0\n",
      "frames_sent_A                                                  2678\n",
      "bss_B_code                                                        B\n",
      "action_ix_B                                                       3\n",
      "status_ix_B                                                       8\n",
      "primary_B                                                         1\n",
      "max_bw_ix_B                                                       1\n",
      "load_ix_B                                                         2\n",
      "load_B                                                       4166.5\n",
      "thr_B                                                          50.1\n",
      "d_B                                                            1.36\n",
      "rts_lost_B                                                        0\n",
      "rts_sent_B                                                     5757\n",
      "frames_lost_B                                                     0\n",
      "frames_sent_B                                                  5757\n",
      "bss_C_code                                                        C\n",
      "action_ix_C                                                       5\n",
      "status_ix_C                                                      14\n",
      "                                        ...                        \n",
      "max_bw_ix_C                                                       1\n",
      "load_ix_C                                                         2\n",
      "load_C                                                       4166.5\n",
      "thr_C                                                         50.15\n",
      "d_C                                                            3.24\n",
      "rts_lost_C                                                        0\n",
      "rts_sent_C                                                     2710\n",
      "frames_lost_C                                                     0\n",
      "frames_sent_C                                                  2710\n",
      "bss_D_code                                                        D\n",
      "action_ix_D                                                       7\n",
      "status_ix_D                                                      20\n",
      "primary_D                                                         3\n",
      "max_bw_ix_D                                                       1\n",
      "load_ix_D                                                         2\n",
      "load_D                                                       4166.5\n",
      "thr_D                                                         50.18\n",
      "d_D                                                            1.36\n",
      "rts_lost_D                                                        0\n",
      "rts_sent_D                                                     5769\n",
      "frames_lost_D                                                     0\n",
      "frames_sent_D                                                  5769\n",
      "sat_A                                                        1.0066\n",
      "sat_B                                                         1.002\n",
      "sat_C                                                         1.003\n",
      "sat_D                                                        1.0036\n",
      "min_sat                                                           1\n",
      "mean_sat                                                          1\n",
      "max_delay                                                      3.37\n",
      "mean_delay                                                     3.37\n",
      "Name: 60328, Length: 61, dtype: object\n",
      "Optimal global configuration: p_A = 0, b_A = 1, p_B = 1, b_B = 1, p_C = 2, b_C = 1, p_D = 3, b_D = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UPF\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:61: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "OPTIMAL_MIN_SAT_MARGIN = 0.00  # if achieved sat >= optimal throughput - OPTIMAL_MIN_SAT_MARGIN, OKAY\n",
    "OPTIMAL_MAX_DELAY_MARGIN = 2\n",
    "\n",
    "# Overview of the filtered dataset\n",
    "print('Overview of the FILTERED dataset (load %d Mbps, metric_to_optimize = \"%s\"):' % (LOAD_MBPS, metric_to_optimize))\n",
    "\n",
    "min_y = df_y_filtered.min()\n",
    "mean_y = df_y_filtered.mean()\n",
    "max_y = df_y_filtered.max()\n",
    "\n",
    "objective_y = df_y_filtered.max()\n",
    "optimal_confs_ix = df_y_filtered.loc[df_y >= (objective_y-OPTIMAL_MIN_SAT_MARGIN)]\n",
    "objective_y_mean = df_y_mean_filtered.max()\n",
    "\n",
    "if metric_to_optimize == 'delay':\n",
    "    # delay ---> minimize\n",
    "    objective_y = df_y_filtered.min()\n",
    "    objective_action_ix = np.argmin(df_y_filtered)\n",
    "    optimal_confs_ix = df_y_filtered.loc[df_y_filtered <= (objective_y + OPTIMAL_MAX_DELAY_MARGIN)]\n",
    "elif metric_to_optimize == 'satis':\n",
    "    # satisfaction ---> maximize\n",
    "    objective_y = df_y_filtered.max()\n",
    "    objective_action_ix = np.argmax(df_y_filtered)\n",
    "    optimal_confs_ix = df_y_filtered.loc[df_y >= (objective_y-OPTIMAL_MIN_SAT_MARGIN)]\n",
    "\n",
    "num_optimal_confs = len(optimal_confs_ix)\n",
    "\n",
    "print('- min = %.2f\\n- mean = %.2f\\n- max = %.2f' % (min_y,mean_y,max_y))\n",
    "print('- objective_y = %.2f' % objective_y)\n",
    "print('- objective_action_ix = %d' % objective_action_ix)\n",
    "print('   * num_optimal_confs = %d/%d (%.2f %%)' % \n",
    "      (num_optimal_confs, num_samples_filtered, num_optimal_confs/num_samples_filtered * 100))\n",
    "\n",
    "\n",
    "# Optimal global configuration ind detail\n",
    "obj_a = df.iloc[objective_action_ix]\n",
    "print('Optimal global configuration:')\n",
    "print(obj_a)\n",
    "\n",
    "print('Optimal global configuration: p_A = %d, b_A = %d, p_B = %d, b_B = %d, p_C = %d, b_C = %d, p_D = %d, b_D = %d' % (obj_a['primary_A'], obj_a['max_bw_ix_A'], obj_a['primary_B'], obj_a['max_bw_ix_B'], obj_a['primary_C'], obj_a['max_bw_ix_C'], obj_a['primary_D'], obj_a['max_bw_ix_D']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML approach: RL agents at the edge\n",
    "Each AP runs a MAB at its own trying to greedely boost its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- BSS A: min = 0.00 - mean = 0.53 - max = 1.00\n",
      "- BSS B: min = 0.00 - mean = 0.76 - max = 1.00\n",
      "- BSS C: min = 0.00 - mean = 0.62 - max = 1.00\n",
      "- BSS D: min = 0.00 - mean = 0.79 - max = 1.00\n"
     ]
    }
   ],
   "source": [
    "print('- BSS A: min = %.2f - mean = %.2f - max = %.2f' % (df_y_A_filtered.min(),df_y_A_filtered.mean(),df_y_A_filtered.max()))\n",
    "print('- BSS B: min = %.2f - mean = %.2f - max = %.2f' % (df_y_B_filtered.min(),df_y_B_filtered.mean(),df_y_B_filtered.max()))\n",
    "print('- BSS C: min = %.2f - mean = %.2f - max = %.2f' % (df_y_C_filtered.min(),df_y_C_filtered.mean(),df_y_C_filtered.max()))\n",
    "print('- BSS D: min = %.2f - mean = %.2f - max = %.2f' % (df_y_D_filtered.min(),df_y_D_filtered.mean(),df_y_D_filtered.max()))\n",
    "\n",
    "df_dataset_dummy = pd.concat([df_x_filtered,df_y_A_filtered,df_y_B_filtered,df_y_C_filtered,df_y_D_filtered],\\\n",
    "                             axis=1, sort=False)\n",
    "\n",
    "df_dataset_dummy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Action space per BSS\n",
    "# - there are 4 possible actions per agent (x2 primary value, x2 max. bw)\n",
    "df_x_A = df[['primary_A', 'max_bw_ix_A']]\n",
    "df_x_A_unique = df_x_A.drop_duplicates()\n",
    "df_x_A_dummy = pd.get_dummies(df_x_A_unique,\\\n",
    "                                   prefix=['primary_A', 'max_bw_ix_A'],\\\n",
    "                                   columns=['primary_A', 'max_bw_ix_A'])\n",
    "\n",
    "df_x_B = df[['primary_B', 'max_bw_ix_B']]\n",
    "df_x_B_unique = df_x_B.drop_duplicates()\n",
    "df_x_B_dummy = pd.get_dummies(df_x_B_unique,\\\n",
    "                                   prefix=['primary_B', 'max_bw_ix_B'],\\\n",
    "                                   columns=['primary_B', 'max_bw_ix_B'])\n",
    "\n",
    "df_x_C = df[['primary_C', 'max_bw_ix_C']]\n",
    "df_x_C_unique = df_x_C.drop_duplicates()\n",
    "df_x_C_dummy = pd.get_dummies(df_x_C_unique,\\\n",
    "                                   prefix=['primary_C', 'max_bw_ix_C'],\\\n",
    "                                   columns=['primary_C', 'max_bw_ix_C'])\n",
    "\n",
    "df_x_D = df[['primary_D', 'max_bw_ix_D']]\n",
    "df_x_D_unique = df_x_D.drop_duplicates()\n",
    "df_x_D_dummy = pd.get_dummies(df_x_D_unique,\\\n",
    "                                   prefix=['primary_D', 'max_bw_ix_D'],\\\n",
    "                                   columns=['primary_D', 'max_bw_ix_D'])\n",
    "\n",
    "# - global action space (considering config of every BSS)\n",
    "df_x_aux = pd.concat([df_x_A, df_x_B, df_x_C, df_x_D], axis=1, sort=False)\n",
    "df_x_unique = df_x_aux.drop_duplicates()\n",
    "df_x_dummy = pd.get_dummies(df_x_unique,\\\n",
    "                                   prefix=['primary_A', 'max_bw_ix_A',\\\n",
    "                                           'primary_B', 'max_bw_ix_B',\\\n",
    "                                           'primary_C', 'max_bw_ix_C',\\\n",
    "                                           'primary_D', 'max_bw_ix_D'],\\\n",
    "                                   columns=['primary_A', 'max_bw_ix_A',\\\n",
    "                                           'primary_B', 'max_bw_ix_B',\\\n",
    "                                           'primary_C', 'max_bw_ix_C',\\\n",
    "                                           'primary_D', 'max_bw_ix_D'])\n",
    "\n",
    "df_x_dummy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#df_dataset_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MABs at the edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for running the MAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,reward_type):\n",
    "\n",
    "    # MAB process:\n",
    "    # - 1. every BSS picks action simultaneously\n",
    "    # - 2. check reward of each BSS by looking the global dataset\n",
    "    # - 3. update MAB with the last reward\n",
    "    # - 4. go to step 1\n",
    "    \n",
    "    print(\"iteration: \", end='')\n",
    "    \n",
    "    for it in range(NUM_ITERATIONS):\n",
    "        \n",
    "        \n",
    "        print(\"%d, \" % it, end='')\n",
    "\n",
    "        # 1. every BSS picks action\n",
    "        action_ix_A = mab_A.select_action()\n",
    "        action_ix_B = mab_B.select_action()\n",
    "        action_ix_C = mab_C.select_action()\n",
    "        action_ix_D = mab_D.select_action()\n",
    "\n",
    "        # 2. check reward\n",
    "        # - convert action index to dummy representation of the status features (primary and max_bw_ix)\n",
    "        action_A_dummy = df_x_A_dummy.iloc[action_ix_A]\n",
    "        action_B_dummy = df_x_B_dummy.iloc[action_ix_B]\n",
    "        action_C_dummy = df_x_C_dummy.iloc[action_ix_C]\n",
    "        action_D_dummy = df_x_D_dummy.iloc[action_ix_D]\n",
    "\n",
    "        action_global = pd.concat([action_A_dummy, action_B_dummy, action_C_dummy, action_D_dummy], axis=0, sort=False)\n",
    "        for i, row in df_x_dummy.iterrows():\n",
    "            if action_global.equals(row):\n",
    "                action_ix_global = i\n",
    "                break\n",
    "        status_reward = df_dataset_dummy.iloc[action_ix_global]\n",
    "        \n",
    "        if reward_type == 'delay':\n",
    "            # delay ---> minimize\n",
    "            MIN_EXPECTED_DELAY = 0.1\n",
    "            r_A = MIN_EXPECTED_DELAY / status_reward['d_A']\n",
    "            r_B = MIN_EXPECTED_DELAY / status_reward['d_B']\n",
    "            r_C = MIN_EXPECTED_DELAY / status_reward['d_C']\n",
    "            r_D = MIN_EXPECTED_DELAY / status_reward['d_D']\n",
    "        \n",
    "        elif reward_type == 'satis':\n",
    "            # satisfaction ---> maximize\n",
    "            r_A = status_reward['sat_A']\n",
    "            r_B = status_reward['sat_B']\n",
    "            r_C = status_reward['sat_C']\n",
    "            r_D = status_reward['sat_D']\n",
    "\n",
    "        # 3. update MAB with the last reward\n",
    "        mab_A.update_reward(action_ix_A, r_A)\n",
    "        mab_B.update_reward(action_ix_B, r_B)\n",
    "        mab_C.update_reward(action_ix_C, r_C)\n",
    "        mab_D.update_reward(action_ix_D, r_D)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RAND_SEED = 1992\n",
    "random.seed(a=RAND_SEED, version=2)\n",
    "NUM_ARMS = 12 # 4 primaries (0,1,2,3) and 3 max bandwidths ixs (1,2,3) corresponding to (20,40,80) MHz\n",
    "NUM_ITERATIONS = 200\n",
    "\n",
    "# create MAB model\n",
    "\n",
    "# mab_A = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"A-eps\")\n",
    "# mab_B = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"B-eps\")\n",
    "# mab_C = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"C-eps\")\n",
    "# mab_D = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"D-eps\")\n",
    "\n",
    "# mab_A = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"A-tsbeta\")\n",
    "# mab_B = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"B-tsbeta\")\n",
    "# mab_C = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"C-tsbeta\")\n",
    "# mab_D = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"D-tsbeta\")\n",
    "\n",
    "# mab_A = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"A-ucb\")\n",
    "# mab_B = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"B-ucb\")\n",
    "# mab_C = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"C-ucb\")\n",
    "# mab_D = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"D-ucb\")\n",
    "\n",
    "# run_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,'satis')\n",
    "\n",
    "# # summary\n",
    "# mab_A.print_summary()\n",
    "# mab_B.print_summary()\n",
    "# mab_C.print_summary()\n",
    "# mab_D.print_summary()\n",
    "\n",
    "mab_A_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"A-explfirst\")\n",
    "mab_B_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"B-explfirst\")\n",
    "mab_C_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"C-explfirst\")\n",
    "mab_D_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"D-explfirst\")\n",
    "\n",
    "mab_A_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"A-eps\")\n",
    "mab_B_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"B-eps\")\n",
    "mab_C_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"C-eps\")\n",
    "mab_D_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"D-eps\")\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 0.95\n",
    "epsilon_original = 1\n",
    "mab_A_slql = mab.Stateless_qlearning(epsilon_original, alpha, gamma, num_arms = NUM_ARMS, name=\"A-slql\")\n",
    "mab_B_slql = mab.Stateless_qlearning(epsilon_original, alpha, gamma, num_arms = NUM_ARMS, name=\"B-slql\")\n",
    "mab_C_slql = mab.Stateless_qlearning(epsilon_original, alpha, gamma, num_arms = NUM_ARMS, name=\"C-slql\")\n",
    "mab_D_slql = mab.Stateless_qlearning(epsilon_original, alpha, gamma, num_arms = NUM_ARMS, name=\"D-slql\")\n",
    "\n",
    "mab_A_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"A-tsbeta\")\n",
    "mab_B_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"B-tsbeta\")\n",
    "mab_C_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"C-tsbeta\")\n",
    "mab_D_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"D-tsbeta\")\n",
    "\n",
    "mab_A_tsnormal = mab.Thompson_sampling_normal(num_arms = NUM_ARMS, distribution=\"normal\", name=\"A-tsnormal\")\n",
    "mab_B_tsnormal = mab.Thompson_sampling_normal(num_arms = NUM_ARMS, distribution=\"normal\", name=\"B-tsnormal\")\n",
    "mab_C_tsnormal = mab.Thompson_sampling_normal(num_arms = NUM_ARMS, distribution=\"normal\", name=\"C-tsnormal\")\n",
    "mab_D_tsnormal = mab.Thompson_sampling_normal(num_arms = NUM_ARMS, distribution=\"normal\", name=\"D-tsnormal\")\n",
    "\n",
    "mab_A_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"A-ucb\")\n",
    "mab_B_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"B-ucb\")\n",
    "mab_C_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"C-ucb\")\n",
    "mab_D_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"D-ucb\")\n",
    "\n",
    "mab_A_exp3 = mab.Exp3_mab(gamma = 0.2, num_arms = NUM_ARMS, name=\"A-exp3\")\n",
    "mab_B_exp3 = mab.Exp3_mab(gamma = 0.2, num_arms = NUM_ARMS, name=\"B-exp3\")\n",
    "mab_C_exp3 = mab.Exp3_mab(gamma = 0.2, num_arms = NUM_ARMS, name=\"C-exp3\")\n",
    "mab_D_exp3 = mab.Exp3_mab(gamma = 0.2, num_arms = NUM_ARMS, name=\"D-exp3\")\n",
    "\n",
    "\n",
    "# print('\\nRuning explfirst:')\n",
    "# run_mab(NUM_ITERATIONS,mab_A_explfirst,mab_B_explfirst,mab_C_explfirst,mab_D_explfirst,metric_to_optimize)\n",
    "# print('\\nRuning eps-greedy:')\n",
    "# run_mab(NUM_ITERATIONS,mab_A_eps,mab_B_eps,mab_C_eps,mab_D_eps,metric_to_optimize)\n",
    "# print('\\nRuning TS-beta:')\n",
    "# run_mab(NUM_ITERATIONS,mab_A_tsbeta,mab_B_tsbeta,mab_C_tsbeta,mab_D_tsbeta,metric_to_optimize)\n",
    "# print('\\nRuning TS-normal:')\n",
    "# run_mab(NUM_ITERATIONS,mab_A_tsnormal,mab_B_tsnormal,mab_C_tsnormal,mab_D_tsnormal,metric_to_optimize)\n",
    "# print('\\nRuning UCB1:')\n",
    "# run_mab(NUM_ITERATIONS,mab_A_ucb,mab_B_ucb,mab_C_ucb,mab_D_ucb,metric_to_optimize)\n",
    "# print('\\nRuning Exp3:')\n",
    "# run_mab(NUM_ITERATIONS,mab_A_exp3,mab_B_exp3,mab_C_exp3,mab_D_exp3,metric_to_optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_mab(mab_A,mab_B,mab_C,mab_D,YLIM_REWARD):\n",
    "    # histogram action reward\n",
    "    x_pos = np.array(range(1,NUM_ARMS+1))\n",
    "    YLIM_PROB = [0, 1]\n",
    "    fig, ax = plt.subplots(2, 4,figsize=(10,5))\n",
    "    ax[0,0].bar(x_pos, mab_A.mean_reward, align='center', alpha=0.5)\n",
    "    ax[0,0].set_xticks(x_pos)\n",
    "    ax[0,0].set_ylabel('mean reward')\n",
    "    ax[0,0].set_title(mab_A.name)\n",
    "    ax[0,0].set_ylim(YLIM_REWARD)\n",
    "    ax[0,0].grid()\n",
    "\n",
    "    prob_hist_A = mab_A.count_action_selected / np.sum(mab_A.count_action_selected)\n",
    "    ax[1,0].bar(x_pos, prob_hist_A, align='center', alpha=0.5)\n",
    "    ax[1,0].set_xticks(x_pos)\n",
    "    ax[1,0].set_xlabel('action ix')\n",
    "    ax[1,0].set_ylabel('prob. pick')\n",
    "    ax[1,0].set_ylim(YLIM_PROB)\n",
    "    ax[1,0].grid()\n",
    "\n",
    "    ax[0,1].bar(x_pos, mab_B.mean_reward, align='center', alpha=0.5)\n",
    "    ax[0,1].set_xticks(x_pos)\n",
    "    ax[0,1].set_title(mab_B.name)\n",
    "    ax[0,1].set_ylim(YLIM_REWARD)\n",
    "    ax[0,1].grid()\n",
    "\n",
    "    ax[1,1].bar(x_pos, mab_B.count_action_selected / np.sum(mab_B.count_action_selected)\\\n",
    "                , align='center', alpha=0.5)\n",
    "    ax[1,1].set_xticks(x_pos)\n",
    "    ax[1,1].set_xlabel('action ix')\n",
    "    ax[1,1].set_ylim(YLIM_PROB)\n",
    "    ax[1,1].grid()\n",
    "\n",
    "    ax[0,2].bar(x_pos, mab_C.mean_reward, align='center', alpha=0.5)\n",
    "    ax[0,2].set_xticks(x_pos)\n",
    "    ax[0,2].set_title(mab_C.name)\n",
    "    ax[0,2].set_ylim(YLIM_REWARD)\n",
    "    ax[0,2].grid()\n",
    "\n",
    "    ax[1,2].bar(x_pos, mab_C.count_action_selected / np.sum(mab_C.count_action_selected)\\\n",
    "                , align='center', alpha=0.5)\n",
    "    ax[1,2].set_xticks(x_pos)\n",
    "    ax[1,2].set_xlabel('action ix')\n",
    "    ax[1,2].set_ylim(YLIM_PROB)\n",
    "    ax[1,2].grid()\n",
    "\n",
    "    ax[0,3].bar(x_pos, mab_D.mean_reward, align='center', alpha=0.5)\n",
    "    ax[0,3].set_xticks(x_pos)\n",
    "    ax[0,3].set_title(mab_D.name)\n",
    "    ax[0,3].set_ylim(YLIM_REWARD)\n",
    "    ax[0,3].grid()\n",
    "\n",
    "    ax[1,3].bar(x_pos, mab_D.count_action_selected / np.sum(mab_D.count_action_selected)\\\n",
    "                , align='center', alpha=0.5)\n",
    "    ax[0,3].set_xticks(x_pos)\n",
    "    ax[1,3].set_xlabel('action ix')\n",
    "    ax[1,3].set_ylim(YLIM_PROB)\n",
    "    ax[1,3].grid()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return prob_hist_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runchart_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_all,opt_all_mean,YLIM_REWARD,name=\"\"):\n",
    "    \n",
    "    # Runchart\n",
    "    iteration_array = np.array(range(1,NUM_ITERATIONS+1))\n",
    "    reward_history_A = mab_A.reward_history\n",
    "    mean_cum_reward_history_A = np.divide(np.cumsum(mab_A.reward_history), iteration_array)\n",
    "    reward_history_B = mab_B.reward_history\n",
    "    mean_cum_reward_history_B = np.divide(np.cumsum(mab_B.reward_history), iteration_array)\n",
    "    reward_history_C = mab_C.reward_history\n",
    "    mean_cum_reward_history_C = np.divide(np.cumsum(mab_C.reward_history), iteration_array)\n",
    "    reward_history_D = mab_D.reward_history\n",
    "    mean_cum_reward_history_D = np.divide(np.cumsum(mab_D.reward_history), iteration_array)\n",
    "\n",
    "    reward_history_min_wlan = np.minimum.reduce(\\\n",
    "                                          [reward_history_A, reward_history_B,reward_history_C,reward_history_D])\n",
    "    mean_cum_reward_history_wlan = np.divide(np.cumsum(reward_history_min_wlan), iteration_array)\n",
    "    \n",
    "    reward_history_mean_wlan = np.mean([reward_history_A, reward_history_B,reward_history_C,reward_history_D], axis=0)\n",
    "    mean_cum_meanreward_history_wlan = np.divide(np.cumsum(reward_history_mean_wlan), iteration_array)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 6,figsize=(20,3))\n",
    "    ax[0].plot(iteration_array, reward_history_A, 'r', label=\"reward\") # plotting t, a separately \n",
    "    ax[0].plot(iteration_array, mean_cum_reward_history_A, 'b', label=\"mean_cum_reward\") # plotting t, b separately \n",
    "    ax[0].plot(iteration_array, opt_A, 'y--', label=\"optimal\")\n",
    "    ax[0].set_xlabel('iteration')\n",
    "    ax[0].set_ylabel('reward')\n",
    "    ax[0].grid()\n",
    "    ax[0].set_title(mab_A.name)\n",
    "    ax[0].set_ylim(YLIM_REWARD)\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(iteration_array, reward_history_B, 'r', label=\"reward\") # plotting t, a separately \n",
    "    ax[1].plot(iteration_array, mean_cum_reward_history_B, 'b', label=\"mean_cum_reward\") # plotting t, b separately \n",
    "    ax[1].plot(iteration_array, opt_B, 'y--', label=\"optimal\")\n",
    "    ax[1].set_xlabel('iteration')\n",
    "    ax[1].set_ylabel('reward')\n",
    "    ax[1].grid()\n",
    "    ax[1].set_title(mab_B.name)\n",
    "    ax[1].set_ylim(YLIM_REWARD)\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[2].plot(iteration_array, reward_history_C, 'r', label=\"reward\") # plotting t, a separately \n",
    "    ax[2].plot(iteration_array, mean_cum_reward_history_C, 'b', label=\"mean_cum_reward\") # plotting t, b separately \n",
    "    ax[2].plot(iteration_array, opt_C, 'y--', label=\"optimal\")\n",
    "    ax[2].set_xlabel('iteration')\n",
    "    ax[2].set_ylabel('reward')\n",
    "    ax[2].grid()\n",
    "    ax[2].set_title(mab_C.name)\n",
    "    ax[2].set_ylim(YLIM_REWARD)\n",
    "    ax[2].legend()\n",
    "\n",
    "    ax[3].plot(iteration_array, reward_history_D, 'r', label=\"reward\")\n",
    "    ax[3].plot(iteration_array, mean_cum_reward_history_D, 'b', label=\"mean_cum_reward\")\n",
    "    ax[3].plot(iteration_array, opt_D, 'y--', label=\"optimal\")\n",
    "    ax[3].set_xlabel('iteration')\n",
    "    ax[3].set_ylabel('reward')\n",
    "    ax[3].grid()\n",
    "    ax[3].set_title(mab_D.name)\n",
    "    ax[3].set_ylim(YLIM_REWARD)\n",
    "    ax[3].legend()\n",
    "\n",
    "    ax[4].plot(iteration_array, reward_history_min_wlan, 'r', label=\"reward\")\n",
    "    ax[4].plot(iteration_array, mean_cum_reward_history_wlan, 'b', label=\"mean_cum_reward\")\n",
    "    ax[4].plot(iteration_array, opt_all, 'y--', label=\"optimal\")\n",
    "    ax[4].set_xlabel('iteration')\n",
    "    ax[4].set_ylabel('reward')\n",
    "    ax[4].grid()\n",
    "    ax[4].set_title('min WLAN')\n",
    "    ax[4].set_ylim(YLIM_REWARD)\n",
    "    ax[4].legend()\n",
    "    \n",
    "    ax[5].plot(iteration_array, reward_history_mean_wlan, 'r', label=\"reward\")\n",
    "    ax[5].plot(iteration_array, mean_cum_meanreward_history_wlan, 'b', label=\"mean_cum_reward\")\n",
    "    ax[5].plot(iteration_array, opt_all_mean, 'y--', label=\"optimal\")\n",
    "    ax[5].set_xlabel('iteration')\n",
    "    ax[5].set_ylabel('reward')\n",
    "    ax[5].grid()\n",
    "    ax[5].set_title('mean WLAN')\n",
    "    ax[5].set_ylim(YLIM_REWARD)\n",
    "    ax[5].legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    # create matrix for each MAB to be saved to txt\n",
    "    summary_array = np.stack((mab_A.reward_history, mab_B.reward_history, mab_C.reward_history,\\\n",
    "                            mab_D.reward_history,reward_history_min_wlan,reward_history_mean_wlan,\\\n",
    "                              mean_cum_reward_history_A, mean_cum_reward_history_B,mean_cum_reward_history_C,\\\n",
    "                              mean_cum_reward_history_D,mean_cum_reward_history_wlan,mean_cum_meanreward_history_wlan,\\\n",
    "                              opt_A,opt_B,opt_C,opt_D,opt_all,opt_all_mean))\n",
    "    \n",
    "        \n",
    "    return summary_array.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runchart_vsoptimal_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_all,YLIM_REWARD):\n",
    "    \n",
    "    # Runchart\n",
    "    iteration_array = np.array(range(1,NUM_ITERATIONS+1))\n",
    "    reward_history_A = mab_A.reward_history\n",
    "    reward_history_B = mab_B.reward_history\n",
    "    reward_history_C = mab_C.reward_history\n",
    "    reward_history_D = mab_D.reward_history\n",
    "    mean_cum_reward_history_D = np.divide(np.cumsum(mab_D.reward_history), iteration_array)\n",
    "\n",
    "    reward_history_min_wlan = reward_history_min_wlan = np.minimum.reduce(\\\n",
    "                                          [reward_history_A, reward_history_B,reward_history_C,reward_history_D])\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 5,figsize=(20,3))\n",
    "    ax[0].plot(iteration_array, np.divide(reward_history_A, opt_A), 'g', label=\"reward\") # plotting t, a separately \n",
    "    ax[0].set_xlabel('iteration')\n",
    "    ax[0].set_ylabel('rho')\n",
    "    ax[0].grid()\n",
    "    ax[0].set_title(mab_A.name)\n",
    "    ax[0].set_ylim(YLIM_REWARD)\n",
    "\n",
    "    ax[1].plot(iteration_array, reward_history_B / opt_B, 'g', label=\"reward\") # plotting t, a separately \n",
    "    ax[1].set_xlabel('iteration')\n",
    "    ax[1].set_ylabel('rho')\n",
    "    ax[1].grid()\n",
    "    ax[1].set_title(mab_B.name)\n",
    "    ax[1].set_ylim(YLIM_REWARD)\n",
    "\n",
    "    ax[2].plot(iteration_array, reward_history_C / opt_C, 'g', label=\"reward\") # plotting t, a separately \n",
    "    ax[2].set_xlabel('iteration')\n",
    "    ax[2].set_ylabel('rho')\n",
    "    ax[2].grid()\n",
    "    ax[2].set_title(mab_C.name)\n",
    "    ax[2].set_ylim(YLIM_REWARD)\n",
    "\n",
    "    ax[3].plot(iteration_array, reward_history_D / opt_D, 'g', label=\"reward\")\n",
    "    ax[3].set_xlabel('iteration')\n",
    "    ax[3].set_ylabel('rho')\n",
    "    ax[3].grid()\n",
    "    ax[3].set_title(mab_D.name)\n",
    "    ax[3].set_ylim(YLIM_REWARD)\n",
    "\n",
    "    ax[4].plot(iteration_array, reward_history_min_wlan / opt_all, 'g', label=\"reward\")\n",
    "    ax[4].set_xlabel('iteration')\n",
    "    ax[4].set_ylabel('rho')\n",
    "    ax[4].grid()\n",
    "    ax[4].set_title('min WLAN')\n",
    "    ax[4].set_ylim(YLIM_REWARD)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YLIM_REWARD = [0, 1.1]\n",
    "\n",
    "opt_A = [df_y_A_filtered.max()] * NUM_ITERATIONS\n",
    "opt_B = [df_y_B_filtered.max()] * NUM_ITERATIONS\n",
    "opt_C = [df_y_C_filtered.max()] * NUM_ITERATIONS\n",
    "opt_D = [df_y_D_filtered.max()] * NUM_ITERATIONS\n",
    "opt_WLAN = [objective_y] * NUM_ITERATIONS\n",
    "opt_WLAN_mean = [objective_y_mean] * NUM_ITERATIONS\n",
    "\n",
    "NUM_SIMULATIONS = 100\n",
    "NUM_ITERATIONS = 200\n",
    "\n",
    "for sim_ix in range(NUM_SIMULATIONS):\n",
    "    print('\\n -------- sim_ix: ', sim_ix)\n",
    "    RAND_SEED = 2002 + sim_ix\n",
    "    random.seed(a=RAND_SEED, version=2)\n",
    "    \n",
    "    mab_A_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"A-eps\")\n",
    "    mab_B_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"B-eps\")\n",
    "    mab_C_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"C-eps\")\n",
    "    mab_D_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"D-eps\")\n",
    "    \n",
    "    run_mab(NUM_ITERATIONS,mab_A_eps,mab_B_eps,mab_C_eps,mab_D_eps,metric_to_optimize)\n",
    "    mab_A = mab_A_eps\n",
    "    mab_B = mab_B_eps\n",
    "    mab_C = mab_C_eps\n",
    "    mab_D = mab_D_eps\n",
    "    filename_root ='epsilon_' + str(RAND_SEED)\n",
    "\n",
    "    prob_hist_A = plot_histogram_mab(mab_A,mab_B,mab_C,mab_D,YLIM_REWARD)\n",
    "    np.savetxt(filename_root+'_prob_hist_A.csv', prob_hist_A, delimiter=',', fmt='%.4f')\n",
    "\n",
    "    if metric_to_optimize == 'satis':\n",
    "        summary_array = plot_runchart_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_WLAN,opt_WLAN_mean,YLIM_REWARD)\n",
    "        np.savetxt(filename_root+'_summary.csv', summary_array, delimiter=',', fmt='%.4f')\n",
    "    else:\n",
    "        MIN_EXPECTED_DELAY = 0.1\n",
    "        mean_cum_reward_history_wlan_explfirst = plot_runchart_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,MIN_EXPECTED_DELAY / objective_y,YLIM_REWARD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q -learning agents at the edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qlearning(NUM_ITERATIONS,q_A,q_B,q_C,q_D,reward_type,num_states):\n",
    "\n",
    "    # MAB process:\n",
    "    # - 1. every BSS picks action simultaneously\n",
    "    # - 2. check reward of each BSS by looking the global dataset\n",
    "    # - 3. update Qlearnings with the last reward\n",
    "    # - 4. go to step 1\n",
    "    \n",
    "    print(\"iteration: \", end='')\n",
    "    \n",
    "    s_new_A, s_new_B, s_new_C, s_new_D = 0, 0, 0, 0\n",
    "    \n",
    "    for it in range(NUM_ITERATIONS):\n",
    "        \n",
    "        s_A = s_new_A\n",
    "        s_B = s_new_B\n",
    "        s_C = s_new_C\n",
    "        s_D = s_new_D\n",
    "        \n",
    "        print(\"%d, \" % it, end='')\n",
    "\n",
    "        # 1. every BSS picks action\n",
    "        action_ix_A = q_A.select_action(s_A)\n",
    "        action_ix_B = q_B.select_action(s_B)\n",
    "        action_ix_C = q_C.select_action(s_C)\n",
    "        action_ix_D = q_D.select_action(s_D)\n",
    "\n",
    "        # 2. check reward\n",
    "        # - convert action index to dummy representation of the status features (primary and max_bw_ix)\n",
    "        action_A_dummy = df_x_A_dummy.iloc[action_ix_A]\n",
    "        action_B_dummy = df_x_B_dummy.iloc[action_ix_B]\n",
    "        action_C_dummy = df_x_C_dummy.iloc[action_ix_C]\n",
    "        action_D_dummy = df_x_D_dummy.iloc[action_ix_D]\n",
    "\n",
    "        action_global = pd.concat([action_A_dummy, action_B_dummy, action_C_dummy, action_D_dummy], axis=0, sort=False)\n",
    "        for i, row in df_x_dummy.iterrows():\n",
    "            if action_global.equals(row):\n",
    "                action_ix_global = i\n",
    "                break\n",
    "        status_reward = df_dataset_dummy.iloc[action_ix_global]\n",
    "        \n",
    "        if reward_type == 'delay':\n",
    "            # delay ---> minimize\n",
    "            MIN_EXPECTED_DELAY = 0.1\n",
    "            r_A = MIN_EXPECTED_DELAY / status_reward['d_A']\n",
    "            r_B = MIN_EXPECTED_DELAY / status_reward['d_B']\n",
    "            r_C = MIN_EXPECTED_DELAY / status_reward['d_C']\n",
    "            r_D = MIN_EXPECTED_DELAY / status_reward['d_D']\n",
    "        \n",
    "        elif reward_type == 'satis':\n",
    "            # satisfaction ---> maximize\n",
    "            r_A = status_reward['sat_A']\n",
    "            r_B = status_reward['sat_B']\n",
    "            r_C = status_reward['sat_C']\n",
    "            r_D = status_reward['sat_D']\n",
    "     \n",
    "        \n",
    "        # State detection\n",
    "        TRESHOLD_SATISFIED = 0.999\n",
    "        satis_A, satis_B, satis_C, satis_D = 0,0,0,0\n",
    "        if r_A > TRESHOLD_SATISFIED:\n",
    "            satis_A = 1\n",
    "        if r_B > TRESHOLD_SATISFIED:\n",
    "            satis_B = 1 \n",
    "        if r_C > TRESHOLD_SATISFIED:\n",
    "            satis_C = 1 \n",
    "        if r_D > TRESHOLD_SATISFIED:\n",
    "            satis_D = 1 \n",
    "        \n",
    "        if num_states == 2:\n",
    "            # - Binary (only satis)\n",
    "            s_new_A, s_new_B, s_new_C, s_new_D = satis_A, satis_B, satis_C, satis_D\n",
    "        elif num_states == 24:\n",
    "            # - Satis + action\n",
    "            NUM_ARMS = 12\n",
    "            s_new_A = (satis_A * NUM_ARMS) + action_ix_A\n",
    "            s_new_B = (satis_B * NUM_ARMS) + action_ix_B\n",
    "            s_new_C = (satis_C * NUM_ARMS) + action_ix_C\n",
    "            s_new_D = (satis_D * NUM_ARMS) + action_ix_D\n",
    "        else:\n",
    "            sys.exit('Invalid number of contexts')\n",
    "            \n",
    "        # 3. update MAB with the last reward\n",
    "        q_A.update_reward(s_A, s_new_A, action_ix_A, r_A)\n",
    "        q_B.update_reward(s_B, s_new_B,action_ix_B, r_B)\n",
    "        q_C.update_reward(s_C, s_new_C,action_ix_C, r_C)\n",
    "        q_D.update_reward(s_D, s_new_D,action_ix_D, r_D)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------- sim_ix:  0\n",
      "\n",
      " * 2-states\n",
      "iteration: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, "
     ]
    }
   ],
   "source": [
    "NUM_ITERATIONS = 200\n",
    "YLIM_REWARD = [0, 1.1]\n",
    "num_arms = NUM_ARMS\n",
    "# alpha = 0.8\n",
    "# gamma = 0.2\n",
    "\n",
    "alpha = 0.9\n",
    "gamma = 0.1\n",
    "\n",
    "opt_A = [df_y_A_filtered.max()] * NUM_ITERATIONS\n",
    "opt_B = [df_y_B_filtered.max()] * NUM_ITERATIONS\n",
    "opt_C = [df_y_C_filtered.max()] * NUM_ITERATIONS\n",
    "opt_D = [df_y_D_filtered.max()] * NUM_ITERATIONS\n",
    "opt_WLAN = [objective_y] * NUM_ITERATIONS\n",
    "opt_WLAN_mean = [objective_y_mean] * NUM_ITERATIONS\n",
    "\n",
    "NUM_SIMULATIONS = 67\n",
    "\n",
    "\n",
    "for sim_ix in range(NUM_SIMULATIONS):\n",
    "\n",
    "    \n",
    "    RAND_SEED = 2025 + sim_ix\n",
    "    print('\\n -------- sim_ix: ', sim_ix)\n",
    "    random.seed(a=RAND_SEED, version=2)\n",
    "\n",
    "    # 2-states\n",
    "    print('\\n * 2-states') \n",
    "    num_states = 2\n",
    "    q_A = Qlearning(epsilon_original, alpha, gamma, num_arms, num_states, name=\"ql_A\")\n",
    "    q_B = Qlearning(epsilon_original, alpha, gamma, num_arms, num_states, name=\"ql_B\")\n",
    "    q_C = Qlearning(epsilon_original, alpha, gamma, num_arms, num_states, name=\"ql_C\")\n",
    "    q_D = Qlearning(epsilon_original, alpha, gamma, num_arms, num_states, name=\"ql_D\")\n",
    "\n",
    "    run_qlearning(NUM_ITERATIONS,q_A,q_B,q_C,q_D,metric_to_optimize,num_states)\n",
    "\n",
    "    mab_A = q_A\n",
    "    mab_B = q_B\n",
    "    mab_C = q_C\n",
    "    mab_D = q_D\n",
    "    filename_root ='qlearning_02states_alpha' + str(alpha) + '_gamma'+ str(gamma) + '_' + str(RAND_SEED)\n",
    "\n",
    "    prob_hist_A = plot_histogram_mab(mab_A,mab_B,mab_C,mab_D,YLIM_REWARD)\n",
    "    np.savetxt(filename_root+'_prob_hist_A.csv', prob_hist_A, delimiter=',', fmt='%.4f')\n",
    "\n",
    "    if metric_to_optimize == 'satis':\n",
    "        summary_array = plot_runchart_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_WLAN,opt_WLAN_mean,YLIM_REWARD)\n",
    "        np.savetxt(filename_root+'_summary.csv', summary_array, delimiter=',', fmt='%.4f')\n",
    "\n",
    "    # 24-states\n",
    "    print('\\n * 24-states') \n",
    "    num_states = 24\n",
    "    q_A_24state = Qlearning(epsilon_original, alpha, gamma, num_arms, num_states, name=\"ql_A\")\n",
    "    q_B_24state = Qlearning(epsilon_original, alpha, gamma, num_arms, num_states, name=\"ql_B\")\n",
    "    q_C_24state = Qlearning(epsilon_original, alpha, gamma, num_arms, num_states, name=\"ql_C\")\n",
    "    q_D_24state = Qlearning(epsilon_original, alpha, gamma, num_arms, num_states, name=\"ql_D\")\n",
    "\n",
    "    run_qlearning(NUM_ITERATIONS,q_A_24state,q_B_24state,q_C_24state,q_D_24state,metric_to_optimize,num_states)\n",
    "\n",
    "    mab_A = q_A_24state\n",
    "    mab_B = q_B_24state\n",
    "    mab_C = q_C_24state\n",
    "    mab_D = q_D_24state\n",
    "    filename_root ='qlearning_24states_alpha' + str(alpha) + '_gamma'+ str(gamma)+ '_' + str(RAND_SEED)\n",
    "\n",
    "    prob_hist_A = plot_histogram_mab(mab_A,mab_B,mab_C,mab_D,YLIM_REWARD)\n",
    "    np.savetxt(filename_root+'_prob_hist_A.csv', prob_hist_A, delimiter=',', fmt='%.4f')\n",
    "\n",
    "    if metric_to_optimize == 'satis':\n",
    "        summary_array = plot_runchart_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_WLAN,opt_WLAN_mean,YLIM_REWARD)\n",
    "        np.savetxt(filename_root+'_summary.csv', summary_array, delimiter=',', fmt='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- End of Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual MABs at the edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_contextual_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,reward_type,num_contexts):\n",
    "\n",
    "    # MAB process:\n",
    "    # - 1. every BSS picks action simultaneously\n",
    "    # - 2. check reward of each BSS by looking the global dataset\n",
    "    # - 3. update Qlearnings with the last reward\n",
    "    # - 4. go to step 1\n",
    "    \n",
    "    print(\"iteration: \", end='')\n",
    "    \n",
    "    c_A, c_B, c_C, c_D = 0, 0, 0, 0\n",
    "    \n",
    "    for it in range(NUM_ITERATIONS):\n",
    "\n",
    "        print(\"%d, \" % it, end='')\n",
    "\n",
    "        # 1. every BSS picks action\n",
    "        action_ix_A = mab_A.select_action(c_A)\n",
    "        action_ix_B = mab_B.select_action(c_B)\n",
    "        action_ix_C = mab_C.select_action(c_C)\n",
    "        action_ix_D = mab_D.select_action(c_D)\n",
    "\n",
    "        # 2. check reward\n",
    "        # - convert action index to dummy representation of the status features (primary and max_bw_ix)\n",
    "        action_A_dummy = df_x_A_dummy.iloc[action_ix_A]\n",
    "        action_B_dummy = df_x_B_dummy.iloc[action_ix_B]\n",
    "        action_C_dummy = df_x_C_dummy.iloc[action_ix_C]\n",
    "        action_D_dummy = df_x_D_dummy.iloc[action_ix_D]\n",
    "\n",
    "        action_global = pd.concat([action_A_dummy, action_B_dummy, action_C_dummy, action_D_dummy], axis=0, sort=False)\n",
    "        for i, row in df_x_dummy.iterrows():\n",
    "            if action_global.equals(row):\n",
    "                action_ix_global = i\n",
    "                break\n",
    "        status_reward = df_dataset_dummy.iloc[action_ix_global]\n",
    "        \n",
    "        if reward_type == 'delay':\n",
    "            # delay ---> minimize\n",
    "            MIN_EXPECTED_DELAY = 0.1\n",
    "            r_A = MIN_EXPECTED_DELAY / status_reward['d_A']\n",
    "            r_B = MIN_EXPECTED_DELAY / status_reward['d_B']\n",
    "            r_C = MIN_EXPECTED_DELAY / status_reward['d_C']\n",
    "            r_D = MIN_EXPECTED_DELAY / status_reward['d_D']\n",
    "        \n",
    "        elif reward_type == 'satis':\n",
    "            # satisfaction ---> maximize\n",
    "            r_A = status_reward['sat_A']\n",
    "            r_B = status_reward['sat_B']\n",
    "            r_C = status_reward['sat_C']\n",
    "            r_D = status_reward['sat_D']\n",
    "            \n",
    "        # 3. update MAB with the last reward\n",
    "        mab_A.update_reward(c_A, action_ix_A, r_A)\n",
    "        mab_B.update_reward(c_B,action_ix_B, r_B)\n",
    "        mab_C.update_reward(c_C,action_ix_C, r_C)\n",
    "        mab_D.update_reward(c_D,action_ix_D, r_D)\n",
    "        \n",
    "        # State detection\n",
    "        TRESHOLD_SATISFIED = 0.999\n",
    "        satis_A, satis_B, satis_C, satis_D = 0,0,0,0\n",
    "        if r_A > TRESHOLD_SATISFIED:\n",
    "            satis_A = 1\n",
    "        if r_B > TRESHOLD_SATISFIED:\n",
    "            satis_B = 1 \n",
    "        if r_C > TRESHOLD_SATISFIED:\n",
    "            satis_C = 1 \n",
    "        if r_D > TRESHOLD_SATISFIED:\n",
    "            satis_D = 1 \n",
    "        \n",
    "        if num_contexts == 2:\n",
    "            # - Binary (only satis)\n",
    "            c_A, c_B, c_C, c_D = satis_A, satis_B, satis_C, satis_D\n",
    "        elif num_contexts == 24:\n",
    "            # - Satis + action\n",
    "            NUM_ARMS = 12\n",
    "            c_A = (satis_A * NUM_ARMS) + action_ix_A\n",
    "            c_B = (satis_B * NUM_ARMS) + action_ix_B\n",
    "            c_C = (satis_C * NUM_ARMS) + action_ix_C\n",
    "            c_D = (satis_D * NUM_ARMS) + action_ix_D\n",
    "        else:\n",
    "            sys.exit('Invalid number of contexts')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YLIM_REWARD = [0, 1.1]\n",
    "\n",
    "opt_A = [df_y_A_filtered.max()] * NUM_ITERATIONS\n",
    "opt_B = [df_y_B_filtered.max()] * NUM_ITERATIONS\n",
    "opt_C = [df_y_C_filtered.max()] * NUM_ITERATIONS\n",
    "opt_D = [df_y_D_filtered.max()] * NUM_ITERATIONS\n",
    "opt_WLAN = [objective_y] * NUM_ITERATIONS\n",
    "opt_WLAN_mean = [objective_y_mean] * NUM_ITERATIONS\n",
    "\n",
    "\n",
    "NUM_SIMULATIONS = 90\n",
    "NUM_ITERATIONS = 200\n",
    "epsilon_original = 1.0\n",
    "\n",
    "for sim_ix in range(NUM_SIMULATIONS):\n",
    "    print('\\n -------- sim_ix: ', sim_ix)\n",
    "    RAND_SEED = 2002 + sim_ix\n",
    "    random.seed(a=RAND_SEED, version=2)\n",
    "\n",
    "    # 2 contexts\n",
    "    num_contexts = 2\n",
    "    mab_A_contegreedy = Contextual_egreedy_mab(epsilon_original, num_arms = NUM_ARMS, name=\"A-contegreedy\")\n",
    "    mab_B_contegreedy = Contextual_egreedy_mab(epsilon_original, num_arms = NUM_ARMS, name=\"B-contegreedy\")\n",
    "    mab_C_contegreedy = Contextual_egreedy_mab(epsilon_original, num_arms = NUM_ARMS, name=\"C-contegreedy\")\n",
    "    mab_D_contegreedy = Contextual_egreedy_mab(epsilon_original, num_arms = NUM_ARMS, name=\"D-contegreedy\")\n",
    "    run_contextual_mab(NUM_ITERATIONS,mab_A_contegreedy,mab_B_contegreedy,mab_C_contegreedy,mab_D_contegreedy,metric_to_optimize,num_contexts)\n",
    "\n",
    "    mab_A = mab_A_contegreedy\n",
    "    mab_B = mab_B_contegreedy\n",
    "    mab_C = mab_C_contegreedy\n",
    "    mab_D = mab_D_contegreedy\n",
    "    filename_root ='contextual_epsilon_02contexts_' + str(RAND_SEED)\n",
    "    \n",
    "    prob_hist_A = plot_histogram_mab(mab_A,mab_B,mab_C,mab_D,YLIM_REWARD)\n",
    "    np.savetxt(filename_root+'_prob_hist_A.csv', prob_hist_A, delimiter=',', fmt='%.4f')\n",
    "\n",
    "    if metric_to_optimize == 'satis':\n",
    "        summary_array = plot_runchart_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_WLAN,opt_WLAN_mean,YLIM_REWARD)\n",
    "        np.savetxt(filename_root+'_summary.csv', summary_array, delimiter=',', fmt='%.4f')\n",
    "    \n",
    "    # 24 contexts\n",
    "    \n",
    "    num_contexts = 24\n",
    "    mab_A_contegreedy_24 = Contextual_egreedy_24_mab(epsilon_original, num_arms = NUM_ARMS, name=\"A-contegreedy_24\")\n",
    "    mab_B_contegreedy_24 = Contextual_egreedy_24_mab(epsilon_original, num_arms = NUM_ARMS, name=\"B-contegreedy_24\")\n",
    "    mab_C_contegreedy_24 = Contextual_egreedy_24_mab(epsilon_original, num_arms = NUM_ARMS, name=\"C-contegreedy_24\")\n",
    "    mab_D_contegreedy_24 = Contextual_egreedy_24_mab(epsilon_original, num_arms = NUM_ARMS, name=\"D-contegreedy_24\")\n",
    "    run_contextual_mab(NUM_ITERATIONS,mab_A_contegreedy_24,mab_B_contegreedy_24,mab_C_contegreedy_24,mab_D_contegreedy_24,metric_to_optimize,num_contexts)\n",
    "\n",
    "    mab_A = mab_A_contegreedy_24\n",
    "    mab_B = mab_B_contegreedy_24\n",
    "    mab_C = mab_C_contegreedy_24\n",
    "    mab_D = mab_D_contegreedy_24\n",
    "    filename_root ='contextual_epsilon_24contexts_' + str(RAND_SEED)\n",
    "    \n",
    "    prob_hist_A = plot_histogram_mab(mab_A,mab_B,mab_C,mab_D,YLIM_REWARD)\n",
    "    np.savetxt(filename_root+'_prob_hist_A.csv', prob_hist_A, delimiter=',', fmt='%.4f')\n",
    "\n",
    "    if metric_to_optimize == 'satis':\n",
    "        summary_array = plot_runchart_mab(NUM_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_WLAN,opt_WLAN_mean,YLIM_REWARD)\n",
    "        np.savetxt(filename_root+'_summary.csv', summary_array, delimiter=',', fmt='%.4f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- End of Contextual MAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_array = np.array(range(1,NUM_ITERATIONS+1))\n",
    "\n",
    "plt.figure(figsize=(4,3), dpi= 80)\n",
    "plt.plot(iteration_array, mean_cum_reward_history_wlan_explfirst, 'b', label=\"explfirst\")\n",
    "plt.plot(iteration_array, mean_cum_reward_history_wlan_eps, 'g', label=\"eps-greedy\")\n",
    "plt.plot(iteration_array, mean_cum_reward_history_wlan_tsbeta, 'c', label=\"tsbeta\")\n",
    "plt.plot(iteration_array, mean_cum_reward_history_wlan_ucb, 'm', label=\"ucb\")\n",
    "plt.plot(iteration_array, mean_cum_reward_history_wlan_exp3, 'r', label=\"exp3\")\n",
    "plt.plot(iteration_array, [objective_y] * NUM_ITERATIONS, 'y--', label=\"optimal\")\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('mean cum reward')    \n",
    "plt.legend()\n",
    "plt.title('min WLAN satisfaction')\n",
    "plt.grid()\n",
    "plt.ylim(YLIM_REWARD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of iterations of the whole simulation\n",
    "NUM_SIMULATION_ITERATIONS = 500\n",
    "# No. of iterations between load triggers (100 or 200)\n",
    "NUM_ITERATIONS_TO_LOAD_TRIGGER = 100\n",
    "# No. of load triggers in the simulation\n",
    "num_load_slots = math.ceil(NUM_SIMULATION_ITERATIONS / NUM_ITERATIONS_TO_LOAD_TRIGGER)\n",
    "\n",
    "RAND_SEED = 1992\n",
    "random.seed(a=RAND_SEED, version=2)\n",
    "\n",
    "NUM_ARMS = 12\n",
    "\n",
    "mab_A_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"A-explfirst\")\n",
    "mab_B_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"B-explfirst\")\n",
    "mab_C_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"C-explfirst\")\n",
    "mab_D_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"D-explfirst\")\n",
    "\n",
    "mab_A_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"A-eps\")\n",
    "mab_B_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"B-eps\")\n",
    "mab_C_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"C-eps\")\n",
    "mab_D_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"D-eps\")\n",
    "\n",
    "mab_A_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"A-tsbeta\")\n",
    "mab_B_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"B-tsbeta\")\n",
    "mab_C_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"C-tsbeta\")\n",
    "mab_D_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"D-tsbeta\")\n",
    "\n",
    "mab_A_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"A-ucb\")\n",
    "mab_B_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"B-ucb\")\n",
    "mab_C_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"C-ucb\")\n",
    "mab_D_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"D-ucb\")\n",
    "\n",
    "mab_A_exp3 = mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"A-exp3\")\n",
    "mab_B_exp3 = mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"B-exp3\")\n",
    "mab_C_exp3 = mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"C-exp3\")\n",
    "mab_D_exp3 = mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"D-exp3\")\n",
    "\n",
    "\n",
    "metric_to_optimize = 'satis'\n",
    "#metric_to_optimize = 'mix'\n",
    "\n",
    "# Optimal metric per iteration\n",
    "opt_A = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "opt_B = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "opt_C = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "opt_D = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "opt_wlan = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "opt_wlan_mean = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "\n",
    "num_action_switch_A_evolution_explfirst = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "num_action_switch_A_evolution_eps = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "num_action_switch_B_evolution_explfirst = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "num_action_switch_B_evolution_eps = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "num_action_switch_C_evolution_explfirst = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "num_action_switch_C_evolution_eps = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "num_action_switch_D_evolution_explfirst = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "num_action_switch_D_evolution_eps = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "\n",
    "# [20, 20, 20, 150] ---> 0.82\n",
    "# [20, 50, 150, 50] ---> 0.793\n",
    "# [20, 150, 20, 20] ---> 0.793\n",
    "# [50,50,50,50] ---> 1.0\n",
    "\n",
    "\n",
    "# Load pattern 1\n",
    "LOADS_HARDCODED = [[50,50,50,50],\n",
    "    [50, 150, 150, 150],\n",
    "    [20, 20, 20, 150],\n",
    "    [150,20,50,50],\n",
    "    [20,20,20,20]]\n",
    "\n",
    "LOADS_HARDCODED = [[50,50,50,50],\n",
    "    [50, 150, 150, 150],\n",
    "    [20, 20, 20, 150],\n",
    "    [150,150,150,150],\n",
    "    [20,20,20,20]]\n",
    "\n",
    "# Load pattern 2\n",
    "# LOADS_HARDCODED = [[20,50,50,50],\n",
    "#     [50, 20, 20, 150],\n",
    "#     [20, 50, 50, 50]]\n",
    "\n",
    "# Load pattern 3\n",
    "# LOADS_HARDCODED = [[20,50,50,20],\n",
    "#     [50, 150, 20, 150],\n",
    "#     [50, 50, 50, 50]]\n",
    "\n",
    "it_ix = 0\n",
    "\n",
    "for load_trigger_ix in range(num_load_slots):\n",
    "\n",
    "    print('- load_trigger_ix: %d / %d' % (load_trigger_ix, num_load_slots-1))\n",
    "\n",
    "    # draw load for each BSS\n",
    "    load_array = LOADS_HARDCODED[load_trigger_ix]\n",
    "    print(\"  * New load triggered: load_array\", load_array)\n",
    "\n",
    "    # filter dataset by load\n",
    "    out_filter = filter_dataset_by_load(df,load_array,metric_to_optimize)\n",
    "    df_x_filtered = out_filter[0]\n",
    "    df_y_filtered = out_filter[1]\n",
    "    df_x_A_dummy = out_filter[2]\n",
    "    df_x_B_dummy = out_filter[3]\n",
    "    df_x_C_dummy = out_filter[4]\n",
    "    df_x_D_dummy = out_filter[5]\n",
    "    df_x_dummy = out_filter[6]\n",
    "    df_dataset_dummy = out_filter[7]\n",
    "    #print(df_x_filtered.head())  # Overview of data set\n",
    "    #print(df_y_filtered.head())  # Overview of data set\n",
    "\n",
    "    # optimal performance\n",
    "    opt_A[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['sat_A'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "    opt_B[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['sat_B'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "    opt_C[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['sat_C'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "    opt_D[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['sat_D'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "    opt_wlan[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['min_sat'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "    opt_wlan_mean[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_mean_filtered.max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "    \n",
    "#     print(\"  * Max performance:\", df_y_filtered['min_sat'].max())\n",
    "    print(\"  * it_ix_trigger (until %d): \" % (NUM_ITERATIONS_TO_LOAD_TRIGGER-1), end='')\n",
    "    # run MABs\n",
    "    for it_ix_trigger in range(NUM_ITERATIONS_TO_LOAD_TRIGGER):\n",
    "        print(\"%d, \" % it_ix_trigger, end='')\n",
    "        run_mab_step(mab_A_explfirst,mab_B_explfirst,mab_C_explfirst,mab_D_explfirst,metric_to_optimize)\n",
    "        run_mab_step(mab_A_eps,mab_B_eps,mab_C_eps,mab_D_eps,metric_to_optimize)\n",
    "        #run_mab_step(mab_A_tsbeta,mab_B_tsbeta,mab_C_tsbeta,mab_D_tsbeta,metric_to_optimize)\n",
    "        #run_mab_step(mab_A_ucb,mab_B_ucb,mab_C_ucb,mab_D_ucb,metric_to_optimize)\n",
    "        #run_mab_step(mab_A_exp3,mab_B_exp3,mab_C_exp3,mab_D_exp3,metric_to_optimize)\n",
    "        \n",
    "        num_action_switch_A_evolution_explfirst[it_ix] = mab_A_explfirst.num_action_switch\n",
    "        num_action_switch_A_evolution_eps[it_ix] = mab_A_eps.num_action_switch\n",
    "        \n",
    "        num_action_switch_B_evolution_explfirst[it_ix] = mab_B_explfirst.num_action_switch\n",
    "        num_action_switch_B_evolution_eps[it_ix] = mab_B_eps.num_action_switch\n",
    "        \n",
    "        num_action_switch_C_evolution_explfirst[it_ix] = mab_C_explfirst.num_action_switch\n",
    "        num_action_switch_C_evolution_eps[it_ix] = mab_C_eps.num_action_switch\n",
    "        \n",
    "        num_action_switch_D_evolution_explfirst[it_ix] = mab_D_explfirst.num_action_switch\n",
    "        num_action_switch_D_evolution_eps[it_ix] = mab_D_eps.num_action_switch\n",
    "        \n",
    "        it_ix = it_ix + 1\n",
    "    print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_action_switch_summary = np.stack((num_action_switch_A_evolution_explfirst, num_action_switch_B_evolution_explfirst,\\\n",
    "                                     num_action_switch_C_evolution_explfirst,num_action_switch_D_evolution_explfirst,\\\n",
    "                                    num_action_switch_A_evolution_eps, num_action_switch_B_evolution_eps,\\\n",
    "                                     num_action_switch_C_evolution_eps,num_action_switch_D_evolution_eps))\n",
    "    \n",
    "        \n",
    "num_action_switch_summary = num_action_switch_summary.transpose()\n",
    "\n",
    "np.savetxt('num_action_switch_summary_varyingload.csv', num_action_switch_summary, delimiter=',', fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YLIM_REWARD = [0, 1.1]\n",
    "\n",
    "mab_A = mab_A_explfirst\n",
    "mab_B = mab_B_explfirst\n",
    "mab_C = mab_C_explfirst\n",
    "mab_D = mab_D_explfirst\n",
    "\n",
    "summary_array = plot_runchart_mab(NUM_SIMULATION_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_wlan,opt_wlan_mean,YLIM_REWARD)\n",
    "\n",
    "np.savetxt('explfirst_varyingload_summary.csv', summary_array, delimiter=',', fmt='%.4f')\n",
    "np.savetxt('explfirst_varyingload_summary.csv', summary_array, delimiter=',', fmt='%.4f')\n",
    "\n",
    "mab_A = mab_A_eps\n",
    "mab_B = mab_B_eps\n",
    "mab_C = mab_C_eps\n",
    "mab_D = mab_D_eps\n",
    "\n",
    "summary_array = plot_runchart_mab(NUM_SIMULATION_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_wlan,opt_wlan_mean,YLIM_REWARD)\n",
    "\n",
    "np.savetxt('eps_varyingload_summary.csv', summary_array, delimiter=',', fmt='%.4f')\n",
    "\n",
    "mab_A = mab_A_tsbeta\n",
    "mab_B = mab_B_tsbeta\n",
    "mab_C = mab_C_tsbeta\n",
    "mab_D = mab_D_tsbeta\n",
    "\n",
    "mean_cum_reward_history_wlan_explfirst = plot_runchart_mab(NUM_SIMULATION_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_wlan,opt_wlan,YLIM_REWARD)\n",
    "\n",
    "\n",
    "mab_A = mab_A_ucb\n",
    "mab_B = mab_B_ucb\n",
    "mab_C = mab_C_ucb\n",
    "mab_D = mab_D_ucb\n",
    "\n",
    "mean_cum_reward_history_wlan_explfirst = plot_runchart_mab(NUM_SIMULATION_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_wlan,opt_wlan,YLIM_REWARD)\n",
    "\n",
    "\n",
    "mab_A = mab_A_exp3\n",
    "mab_B = mab_B_exp3\n",
    "mab_C = mab_C_exp3\n",
    "mab_D = mab_D_exp3\n",
    "\n",
    "mean_cum_reward_history_wlan_explfirst = plot_runchart_mab(NUM_SIMULATION_ITERATIONS,mab_A,mab_B,mab_C,mab_D,opt_A,opt_B,opt_C,opt_D,opt_wlan,opt_wlan,YLIM_REWARD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab_A.reward_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *** Temporal changes in traffic load ***\n",
    "\n",
    "Variables:\n",
    "- `NUM_SIMULATION_ITERATIONS`: number of iterations of the whole simulation. FIXED.\n",
    "- `NUM_ITERATIONS_TO_LOAD_TRIGGER`: number of iterations between load slots (or load triggers) where new loads are drawn from a probability distribution. FIXED.\n",
    "- `num_load_slots`: number of load slots (or load triggers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of iterations of the whole simulation\n",
    "NUM_SIMULATION_ITERATIONS = 1000\n",
    "# No. of iterations between load triggers (100 or 200)\n",
    "NUM_ITERATIONS_TO_LOAD_TRIGGER = 200\n",
    "# No. of load triggers in the simulation\n",
    "num_load_slots = math.ceil(NUM_SIMULATION_ITERATIONS / NUM_ITERATIONS_TO_LOAD_TRIGGER)\n",
    "\n",
    "LOADS_MBPS = [20, 50, 150]\n",
    "\n",
    "RAND_SEED = 1992\n",
    "random.seed(a=RAND_SEED, version=2)\n",
    "\n",
    "NUM_SIMULATIONS = 10\n",
    "\n",
    "opt_A_allsims = [[-1] * NUM_SIMULATION_ITERATIONS] * NUM_SIMULATIONS\n",
    "opt_B_allsims = [[-1] * NUM_SIMULATION_ITERATIONS] * NUM_SIMULATIONS\n",
    "opt_C_allsims = [[-1] * NUM_SIMULATION_ITERATIONS] * NUM_SIMULATIONS\n",
    "opt_D_allsims = [[-1] * NUM_SIMULATION_ITERATIONS] * NUM_SIMULATIONS\n",
    "opt_wlan_allsims = [[-1] * NUM_SIMULATION_ITERATIONS] * NUM_SIMULATIONS\n",
    "\n",
    "NUM_ARMS = 12\n",
    "\n",
    "mab_A_explfirst_allsims = [mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"A-explfirst\")] * NUM_SIMULATIONS\n",
    "mab_B_explfirst_allsims = [mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"B-explfirst\")] * NUM_SIMULATIONS\n",
    "mab_C_explfirst_allsims = [mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"C-explfirst\")] * NUM_SIMULATIONS\n",
    "mab_D_explfirst_allsims = [mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"D-explfirst\")] * NUM_SIMULATIONS\n",
    "\n",
    "mab_A_eps_allsims = [mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"A-eps\")] * NUM_SIMULATIONS\n",
    "mab_B_eps_allsims = [mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"B-eps\")] * NUM_SIMULATIONS\n",
    "mab_C_eps_allsims = [mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"C-eps\")] * NUM_SIMULATIONS\n",
    "mab_D_eps_allsims = [mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"D-eps\")] * NUM_SIMULATIONS\n",
    "\n",
    "mab_A_tsbeta_allsims = [mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"A-tsbeta\")] * NUM_SIMULATIONS \n",
    "mab_B_tsbeta_allsims = [mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"B-tsbeta\")] * NUM_SIMULATIONS \n",
    "mab_C_tsbeta_allsims = [mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"C-tsbeta\")] * NUM_SIMULATIONS \n",
    "mab_D_tsbeta_allsims = [mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"D-tsbeta\")] * NUM_SIMULATIONS \n",
    "\n",
    "mab_A_ucb_allsims = [mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"A-tsbeta\")] * NUM_SIMULATIONS \n",
    "mab_B_ucb_allsims = [mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"B-tsbeta\")] * NUM_SIMULATIONS \n",
    "mab_C_ucb_allsims = [mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"C-tsbeta\")] * NUM_SIMULATIONS \n",
    "mab_D_ucb_allsims = [mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"D-tsbeta\")] * NUM_SIMULATIONS \n",
    "\n",
    "mab_A_exp3_allsims = [mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"A-exp3\")] * NUM_SIMULATIONS \n",
    "mab_B_exp3_allsims = [mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"B-exp3\")] * NUM_SIMULATIONS \n",
    "mab_C_exp3_allsims = [mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"C-exp3\")] * NUM_SIMULATIONS \n",
    "mab_D_exp3_allsims = [mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"D-exp3\")] * NUM_SIMULATIONS \n",
    "\n",
    "\n",
    "for simulation_ix in range(NUM_SIMULATIONS):\n",
    "\n",
    "    print('simulation_ix: %d / %d' % (simulation_ix, NUM_SIMULATIONS-1))\n",
    "    \n",
    "    NUM_ARMS = 12\n",
    "\n",
    "    mab_A_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"A-explfirst\")\n",
    "    mab_B_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"B-explfirst\")\n",
    "    mab_C_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"C-explfirst\")\n",
    "    mab_D_explfirst = mab.Explfirst_mab(num_arms = NUM_ARMS, name=\"D-explfirst\")\n",
    "    \n",
    "    mab_A_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"A-eps\")\n",
    "    mab_B_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"B-eps\")\n",
    "    mab_C_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"C-eps\")\n",
    "    mab_D_eps = mab.Epsilongreedy_mab(epsilon_original = 1, num_arms = NUM_ARMS, name=\"D-eps\")\n",
    "\n",
    "    mab_A_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"A-tsbeta\")\n",
    "    mab_B_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"B-tsbeta\")\n",
    "    mab_C_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"C-tsbeta\")\n",
    "    mab_D_tsbeta = mab.Thompson_sampling_mab(num_arms = NUM_ARMS, distribution=\"beta\", name=\"D-tsbeta\")\n",
    "    \n",
    "    mab_A_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"A-ucb\")\n",
    "    mab_B_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"B-ucb\")\n",
    "    mab_C_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"C-ucb\")\n",
    "    mab_D_ucb = mab.UCB1_mab(num_arms = NUM_ARMS, name=\"D-ucb\")\n",
    "\n",
    "    mab_A_exp3 = mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"A-exp3\")\n",
    "    mab_B_exp3 = mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"B-exp3\")\n",
    "    mab_C_exp3 = mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"C-exp3\")\n",
    "    mab_D_exp3 = mab.Exp3_mab(gamma = 0.1, num_arms = NUM_ARMS, name=\"D-exp3\")\n",
    "\n",
    "\n",
    "    metric_to_optimize = 'satis'\n",
    "\n",
    "    # Optimal metric per iteration\n",
    "    opt_A = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "    opt_B = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "    opt_C = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "    opt_D = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "    opt_wlan = [-1] * NUM_SIMULATION_ITERATIONS\n",
    "\n",
    "    it_ix = 0\n",
    "\n",
    "    for load_trigger_ix in range(num_load_slots):\n",
    "\n",
    "        print('- load_trigger_ix: %d / %d' % (load_trigger_ix, num_load_slots-1))\n",
    "\n",
    "        # draw load for each BSS\n",
    "        load_array = draw_loads(LOADS_MBPS)\n",
    "        print(\"  * New load triggered: load_array\", load_array)\n",
    "\n",
    "        # filter dataset by load\n",
    "        out_filter = filter_dataset_by_load(df,load_array,metric_to_optimize)\n",
    "        df_x_filtered = out_filter[0]\n",
    "        df_y_filtered = out_filter[1]\n",
    "        df_x_A_dummy = out_filter[2]\n",
    "        df_x_B_dummy = out_filter[3]\n",
    "        df_x_C_dummy = out_filter[4]\n",
    "        df_x_D_dummy = out_filter[5]\n",
    "        df_x_dummy = out_filter[6]\n",
    "        df_dataset_dummy = out_filter[7]\n",
    "        #print(df_x_filtered.head())  # Overview of data set\n",
    "        #print(df_y_filtered.head())  # Overview of data set\n",
    "\n",
    "        # optimal performance\n",
    "        opt_A[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['sat_A'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "        opt_B[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['sat_B'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "        opt_C[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['sat_C'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "        opt_D[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['sat_D'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "        opt_wlan[it_ix:(it_ix + NUM_ITERATIONS_TO_LOAD_TRIGGER)] = [df_y_filtered['min_sat'].max()] * NUM_ITERATIONS_TO_LOAD_TRIGGER\n",
    "        print(\"  * Max performance:\", df_y_filtered['min_sat'].max())\n",
    "        print(\"  * it_ix_trigger (until %d): \" % (NUM_ITERATIONS_TO_LOAD_TRIGGER-1), end='')\n",
    "        # run MABs\n",
    "        for it_ix_trigger in range(NUM_ITERATIONS_TO_LOAD_TRIGGER):\n",
    "            print(\"%d, \" % it_ix, end='')\n",
    "            run_mab_step(mab_A_explfirst,mab_B_explfirst,mab_C_explfirst,mab_D_explfirst,metric_to_optimize)\n",
    "            run_mab_step(mab_A_eps,mab_B_eps,mab_C_eps,mab_D_eps,metric_to_optimize)\n",
    "            run_mab_step(mab_A_tsbeta,mab_B_tsbeta,mab_C_tsbeta,mab_D_tsbeta,metric_to_optimize)\n",
    "            run_mab_step(mab_A_ucb,mab_B_ucb,mab_C_ucb,mab_D_ucb,metric_to_optimize)\n",
    "            run_mab_step(mab_A_exp3,mab_B_exp3,mab_C_exp3,mab_D_exp3,metric_to_optimize)\n",
    "            it_ix = it_ix + 1\n",
    "        print(\" \")\n",
    "    \n",
    "    # store optimal values\n",
    "    opt_A_allsims[simulation_ix] = opt_A\n",
    "    opt_B_allsims[simulation_ix] = opt_B\n",
    "    opt_C_allsims[simulation_ix] = opt_C\n",
    "    opt_D_allsims[simulation_ix] = opt_D\n",
    "    opt_wlan_allsims[simulation_ix] = opt_wlan\n",
    "    \n",
    "    # store MABs\n",
    "    mab_A_explfirst_allsims[simulation_ix] = mab_A_explfirst\n",
    "    mab_B_explfirst_allsims[simulation_ix] = mab_B_explfirst\n",
    "    mab_C_explfirst_allsims[simulation_ix] = mab_C_explfirst\n",
    "    mab_D_explfirst_allsims[simulation_ix] = mab_D_explfirst\n",
    "    \n",
    "    mab_A_eps_allsims[simulation_ix] = mab_A_eps\n",
    "    mab_B_eps_allsims[simulation_ix] = mab_B_eps\n",
    "    mab_C_eps_allsims[simulation_ix] = mab_C_eps\n",
    "    mab_D_eps_allsims[simulation_ix] = mab_D_eps\n",
    "    \n",
    "    mab_A_tsbeta_allsims[simulation_ix] = mab_A_tsbeta\n",
    "    mab_B_tsbeta_allsims[simulation_ix] = mab_B_tsbeta\n",
    "    mab_C_tsbeta_allsims[simulation_ix] = mab_C_tsbeta\n",
    "    mab_D_tsbeta_allsims[simulation_ix] = mab_D_tsbeta\n",
    "    \n",
    "    mab_A_ucb_allsims[simulation_ix] = mab_A_ucb\n",
    "    mab_B_ucb_allsims[simulation_ix] = mab_B_ucb\n",
    "    mab_C_ucb_allsims[simulation_ix] = mab_C_ucb\n",
    "    mab_D_ucb_allsims[simulation_ix] = mab_D_ucb\n",
    "    \n",
    "    mab_A_exp3_allsims[simulation_ix] = mab_A_exp3\n",
    "    mab_B_exp3_allsims[simulation_ix] = mab_B_exp3\n",
    "    mab_C_exp3_allsims[simulation_ix] = mab_C_exp3\n",
    "    mab_D_exp3_allsims[simulation_ix] = mab_D_exp3\n",
    "\n",
    "print('Simulation finished! :D')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
